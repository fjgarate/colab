{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjgarate/colab/blob/main/Dickens_zephyr7b_beta_pre_finetuning_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb1aLHZRFrwA"
      },
      "source": [
        "# **Dickens: the LLM that writes Great Expectations** 泗圭n",
        "\n",
        "In this notebook, we will create a fine-tuned version of Zephyr 7B Beta, called Dickens-Zephyr7B-beta. This LLM will receive natural language, related to data quality, and will output Great Expectations. In this initial version, only core Great Expectations will be presented. For a full list of expectations available check: https://greatexpectations.io/expectations/\n",
        "\n",
        "## Important notice\n",
        "\n",
        "The original notebook has been split into two notebooks. Otherwise, it would fail with \"Out of Memory error\" when running in free colab tier.\n",
        "\n",
        "- Notebook 1 (this one): explains the problem we are trying to solve, plus some initial tests without fine-tuning.\n",
        "- Notebook 2 ([link](https://colab.research.google.com/drive/1P30YSoemEoeaLACyJqzk-M15SGR2mYpW?usp=sharing)): introduces the Dickens dataset plus the fine-tuning code.\n",
        "\n",
        "Feel free to check both sequentially to reproduce the whole experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWzGlJcideZQ"
      },
      "source": [
        "# **Example: Using Dickens LLM for Great Expectations Generation** 汳ｻ\n",
        "\n",
        "In this notebook, the model will take natural language as input, and should a valid customized expectation. Following the original Ludwig notebook, we will first try using the base model with prompting, then  instruction-fine-tune the model.\n",
        "\n",
        "As an example, if we prompt the model with this instruction:\n",
        "\n",
        "```\n",
        "Instruction: DIVISION names should be either the values NSA or start by D.\n",
        "```\n",
        "\n",
        "We want the model to produce exactly this response:\n",
        "\n",
        "```\n",
        "Response: expect_column_values_to_match_regex(column='DIVISION',regex='NSA|^D.*')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXMVoEFkPXJJ"
      },
      "source": [
        "### **Install Ludwig and Ludwig's LLM related dependencies.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiZYaiRufHfh"
      },
      "source": [
        "Install Ludwig from the latest release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvL1cL6wYtWz",
        "outputId": "ca7a2fcb-65d9-43c1-b030-a73b32d65d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m笏≫煤笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.2/1.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[91m笊ｸ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.6/42.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m863.2/863.2 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.5/58.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m165.5/165.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.8/64.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.6/62.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.4/62.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.2/56.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.2/56.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m283.1/283.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m72.8/72.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ludwig (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ptitprince (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2023.3.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m941.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2023.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow --quiet\n",
        "!pip install ludwig[full] --quiet\n",
        "#!pip install ludwig[full]==0.9.1 --quiet\n",
        "!pip install fastapi --quiet\n",
        "!pip install tiktoken --quiet\n",
        "!pip install cohere --quiet\n",
        "!pip install --upgrade git+https://github.com/huggingface/peft.git --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2SRHcKAJYuu"
      },
      "source": [
        "Enable text wrapping so we don't have to scroll horizontally and create a function to flush CUDA cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht4eVWxB13QL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "# get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "def clear_cache():\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3jaU4JBgqZE"
      },
      "source": [
        "Setup Weights & Biases to track our experiments' performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erervkGdgqZE",
        "outputId": "acbc345a-76b1-4d11-c76f-db19bbc2b815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install wandb timm fastprogress transformers datasets -Uqqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNK_o9BKgqZE"
      },
      "outputs": [],
      "source": [
        "# Setting up base Weights and Biases configuration. We import the library here, so we don't get any errors or warnings downstream\n",
        "import wandb\n",
        "\n",
        "# To enable logging the results, set WANDB_MODE = True\n",
        "WANDB_MODE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPWf3FRPgqZE"
      },
      "outputs": [],
      "source": [
        "if WANDB_MODE:\n",
        "  wandb.login()\n",
        "\n",
        "# Our baseline configuration will use the HuggingFaceH4/zephyr-7b-beta model, and the BirdiDQ dataset\n",
        "  wandb.init(\n",
        "    project=\"dickens-zephyr\",\n",
        "    config={\n",
        "        \"model\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "        \"dataset\": \"BirdiDQ dataset\",\n",
        "        })\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV0D2rjRbk4z"
      },
      "source": [
        "### **Import The Code Generation Dataset** 沒欺n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8FXsCwYbkHh",
        "outputId": "5ab1024d-92ab-4b96-88d1-94228e675a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252 entries, 0 to 251\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   prompt      252 non-null    object\n",
            " 1   completion  252 non-null    object\n",
            " 2   split       252 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import data_table; data_table.enable_dataframe_formatter()\n",
        "import numpy as np; np.random.seed(123)\n",
        "import pandas as pd\n",
        "\n",
        "birdi_df = pd.read_json(\"https://raw.githubusercontent.com/BirdiD/BirdiDQ/master/great_expectations/finetuning_template/data/train.json\")\n",
        "\n",
        "# We're going to create a new column called `split` where:\n",
        "# 80% will be assigned a value of 0 -> train set\n",
        "# 10% will be assigned a value of 1 -> validation set\n",
        "# 10% will be assigned a value of 2 -> test set\n",
        "\n",
        "# Calculate the number of rows for each split value\n",
        "total_rows = len(birdi_df)\n",
        "split_0_count = int(total_rows * 0.8)\n",
        "split_1_count = int(total_rows * 0.1)\n",
        "split_2_count = total_rows - split_0_count - split_1_count\n",
        "\n",
        "# Create an array with split values based on the counts\n",
        "split_values = np.concatenate([\n",
        "    np.zeros(split_0_count),\n",
        "    np.ones(split_1_count),\n",
        "    np.full(split_2_count, 2)\n",
        "])\n",
        "\n",
        "# Shuffle the array to ensure randomness\n",
        "np.random.shuffle(split_values)\n",
        "\n",
        "# Add the 'split' column to the DataFrame\n",
        "birdi_df['split'] = split_values\n",
        "birdi_df['split'] = birdi_df['split'].astype(int)\n",
        "\n",
        "# Given the dataset is only 250 examples, we will the whole file\n",
        "birdi_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4CWtqYSgqZE"
      },
      "outputs": [],
      "source": [
        "# export birdi_df to csv\n",
        "birdi_df.to_csv('birdi_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew1H1nbDj9_Q"
      },
      "source": [
        "## **Understanding The Original BirdiDQ Dataset** 沒暴n",
        "\n",
        "The original dataset to fine-tune the Great Expectations is available at https://raw.githubusercontent.com/BirdiD/BirdiDQ/master/great_expectations/finetuning_template/data/train.json under a Apache 2.0 license.\n",
        "\n",
        "Let's take a look to the data!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "dAj8Zdr_F-kQ",
        "outputId": "c4de2a0d-e667-40b0-caa8-dfa427d5a36f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt  \\\n",
              "0  Ensure that MIT University graduate proportion...   \n",
              "1  Check that at least 50% of the values in the s...   \n",
              "2  Verify if the values in the price column are n...   \n",
              "3  Does the median value of revenue, for records ...   \n",
              "4  Verify if the values in the description column...   \n",
              "5  Check that none of the values in the name colu...   \n",
              "6  Verify if the values in the revenue column are...   \n",
              "7  Check if the values in the event_time column m...   \n",
              "8  Check that in 85% of the cases, the values in ...   \n",
              "9  Verify that the lengths of values in the title...   \n",
              "\n",
              "                                          completion  split  \n",
              "0  expect_column_proportion_of_unique_values_to_b...      1  \n",
              "1  expect_column_values_to_be_between(column='sal...      1  \n",
              "2  expect_column_values_to_not_be_null_and_column...      1  \n",
              "3  expect_column_median_to_be_between(column='rev...      0  \n",
              "4  expect_column_values_to_not_be_in_set(column='...      2  \n",
              "5  expect_column_values_to_not_match_regex(column...      0  \n",
              "6  expect_column_pair_values_a_to_be_greater_than...      0  \n",
              "7  expect_column_values_to_match_strftime_format(...      1  \n",
              "8  expect_column_values_to_be_null(column='salary...      0  \n",
              "9  expect_column_value_lengths_to_be_between(colu...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdfc40f0-154b-4529-999b-c13d4730b008\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensure that MIT University graduate proportion...</td>\n",
              "      <td>expect_column_proportion_of_unique_values_to_b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Check that at least 50% of the values in the s...</td>\n",
              "      <td>expect_column_values_to_be_between(column='sal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Verify if the values in the price column are n...</td>\n",
              "      <td>expect_column_values_to_not_be_null_and_column...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does the median value of revenue, for records ...</td>\n",
              "      <td>expect_column_median_to_be_between(column='rev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Verify if the values in the description column...</td>\n",
              "      <td>expect_column_values_to_not_be_in_set(column='...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Check that none of the values in the name colu...</td>\n",
              "      <td>expect_column_values_to_not_match_regex(column...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Verify if the values in the revenue column are...</td>\n",
              "      <td>expect_column_pair_values_a_to_be_greater_than...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Check if the values in the event_time column m...</td>\n",
              "      <td>expect_column_values_to_match_strftime_format(...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Check that in 85% of the cases, the values in ...</td>\n",
              "      <td>expect_column_values_to_be_null(column='salary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Verify that the lengths of values in the title...</td>\n",
              "      <td>expect_column_value_lengths_to_be_between(colu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdfc40f0-154b-4529-999b-c13d4730b008')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdfc40f0-154b-4529-999b-c13d4730b008 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdfc40f0-154b-4529-999b-c13d4730b008');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4745c6c8-d4fb-481b-8a7a-d86879fe052d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4745c6c8-d4fb-481b-8a7a-d86879fe052d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4745c6c8-d4fb-481b-8a7a-d86879fe052d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "birdi_df",
              "summary": "{\n  \"name\": \"birdi_df\",\n  \"rows\": 252,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 252,\n        \"samples\": [\n          \"Check that none of the values in the address column match the pattern for an address starting with a digit.\",\n          \"Verify if the values in the revenue column are consistently higher than the values in the expenses column.\",\n          \"Check if the values in the email column are not 'test@example.com' or 'dummy@example.com'.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 252,\n        \"samples\": [\n          \"expect_column_values_to_not_match_regex(column='address', regex='^(?!\\\\d)\\\\w+(\\\\s\\\\w+){1,2}$')\",\n          \"expect_column_pair_values_a_to_be_greater_than_b(column_A='revenue', column_B='expenses')\",\n          \"expect_column_values_to_not_be_in_set(column='email', value_set=['test@example.com', 'dummy@example.com'])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "birdi_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOW5fIpGGKf3"
      },
      "source": [
        "Each row in the dataset consists of an:\n",
        "- `prompt` that describe the data quality requirements\n",
        "- `completion` that provides the expectation rule with the given parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eIyMPoSGFAN"
      },
      "source": [
        "Now, we will extract the distribution of the expectations used in this original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REqFr-ngx0et",
        "outputId": "1831aa3c-dbb1-46e9-9450-f70cfecadeb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "expect_column_values_to_not_be_null_and_column_to_not_be_empty: 16\n",
            "expect_column_values_to_not_be_in_set: 16\n",
            "expect_column_values_to_be_between: 15\n",
            "expect_column_values_to_match_strftime_format: 15\n",
            "expect_column_values_to_be_unique: 15\n",
            "expect_column_to_exist: 15\n",
            "expect_column_values_to_match_regex: 15\n",
            "expect_column_values_to_not_be_null: 14\n",
            "expect_column_values_to_be_null: 10\n",
            "expect_column_pair_values_a_to_be_greater_than_b: 8\n",
            "expect_column_values_to_be_in_set: 8\n",
            "expect_column_proportion_of_unique_values_to_be_between: 6\n",
            "expect_column_value_lengths_to_be_between: 6\n",
            "expect_column_most_common_value_to_be_in_set: 6\n",
            "expect_column_median_to_be_between: 5\n",
            "expect_column_values_to_not_match_regex: 5\n",
            "expect_column_quantile_values_to_be_between: 5\n",
            "expect_column_pair_values_to_be_in_set: 5\n",
            "expect_column_values_to_be_increasing: 5\n",
            "expect_column_mean_to_be_between: 5\n",
            "expect_column_values_to_not_match_regex_list: 5\n",
            "expect_column_values_to_be_decreasing: 5\n",
            "expect_column_unique_value_count_to_be_between: 5\n",
            "expect_column_pair_values_to_be_equal: 5\n",
            "expect_column_value_z_scores_to_be_less_than: 5\n",
            "expect_column_sum_to_be_between: 5\n",
            "expect_column_value_lengths_to_equal: 5\n",
            "expect_column_max_to_be_between: 4\n",
            "expect_column_min_to_be_between: 4\n",
            "expect_column_distinct_values_to_contain_set: 4\n",
            "expect_column_distinct_values_to_equal_set: 4\n",
            "expect_column_stdev_to_be_between: 3\n",
            "expect_column_distinct_values_to_be_in_set: 3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def extract_function_names(completion_series):\n",
        "    \"\"\"\n",
        "    Extract Python function names from a pandas Series using regular expressions.\n",
        "\n",
        "    :param completion_series: pandas Series containing strings with function calls\n",
        "    :return: List of extracted function names\n",
        "    \"\"\"\n",
        "    # Regular expression pattern for Python function names\n",
        "    pattern = r\"\\b\\w+\\b(?=\\()\"\n",
        "\n",
        "    # Extract all matches\n",
        "    function_names = []\n",
        "    for item in completion_series:\n",
        "        matches = re.findall(pattern, item)\n",
        "        function_names.extend(matches)\n",
        "\n",
        "    return function_names\n",
        "\n",
        "def calculate_frequency(function_names):\n",
        "    \"\"\"\n",
        "    Calculate the frequency of each function name in a list.\n",
        "\n",
        "    :param function_names: List of function names\n",
        "    :return: Dictionary with function names as keys and their frequencies as values\n",
        "    \"\"\"\n",
        "    return Counter(function_names)\n",
        "\n",
        "birdi_df_function_names = extract_function_names(birdi_df['completion'])\n",
        "birdi_df_frequency_count = calculate_frequency(birdi_df_function_names)\n",
        "\n",
        "sorted_frequency_count = dict(sorted(birdi_df_frequency_count.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "for function, count in sorted_frequency_count.items():\n",
        "    print(f\"{function}: {count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mp400dygqZE",
        "outputId": "163f7447-8fd3-4752-ed94-5bfa3fb4adb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary Information:\n",
            "   Total Rows in DataFrame  Number of Different Functions\n",
            "0                      252                             33\n"
          ]
        }
      ],
      "source": [
        "# Summarize the dataset\n",
        "\n",
        "summary_data = {\n",
        "    \"Total Rows in DataFrame\": [len(birdi_df)],\n",
        "    \"Number of Different Functions\": [len(sorted_frequency_count)]\n",
        "}\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\nSummary Information:\")\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYr23uawgqZF",
        "outputId": "fef11d83-fbfd-4eb2-cf83-220893e8fab0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['expect_column_bootstrapped_ks_test_p_value_to_be_greater_than',\n",
              " 'expect_column_chisquare_test_p_value_to_be_greater_than',\n",
              " 'expect_column_distinct_values_to_be_in_set',\n",
              " 'expect_column_distinct_values_to_contain_set',\n",
              " 'expect_column_distinct_values_to_equal_set',\n",
              " 'expect_column_kl_divergence_to_be_less_than',\n",
              " 'expect_column_max_to_be_between',\n",
              " 'expect_column_mean_to_be_between',\n",
              " 'expect_column_median_to_be_between',\n",
              " 'expect_column_min_to_be_between',\n",
              " 'expect_column_most_common_value_to_be_in_set',\n",
              " 'expect_column_pair_cramers_phi_value_to_be_less_than',\n",
              " 'expect_column_pair_values_a_to_be_greater_than_b',\n",
              " 'expect_column_pair_values_to_be_equal',\n",
              " 'expect_column_pair_values_to_be_in_set',\n",
              " 'expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than',\n",
              " 'expect_column_proportion_of_unique_values_to_be_between',\n",
              " 'expect_column_quantile_values_to_be_between',\n",
              " 'expect_column_stdev_to_be_between',\n",
              " 'expect_column_sum_to_be_between',\n",
              " 'expect_column_to_exist',\n",
              " 'expect_column_unique_value_count_to_be_between',\n",
              " 'expect_column_value_lengths_to_be_between',\n",
              " 'expect_column_value_lengths_to_equal',\n",
              " 'expect_column_value_z_scores_to_be_less_than',\n",
              " 'expect_column_values_to_be_between',\n",
              " 'expect_column_values_to_be_dateutil_parseable',\n",
              " 'expect_column_values_to_be_decreasing',\n",
              " 'expect_column_values_to_be_in_set',\n",
              " 'expect_column_values_to_be_in_type_list',\n",
              " 'expect_column_values_to_be_increasing',\n",
              " 'expect_column_values_to_be_json_parseable',\n",
              " 'expect_column_values_to_be_null',\n",
              " 'expect_column_values_to_be_of_type',\n",
              " 'expect_column_values_to_be_unique',\n",
              " 'expect_column_values_to_match_json_schema',\n",
              " 'expect_column_values_to_match_like_pattern_list',\n",
              " 'expect_column_values_to_match_like_pattern',\n",
              " 'expect_column_values_to_match_regex_list',\n",
              " 'expect_column_values_to_match_regex',\n",
              " 'expect_column_values_to_match_strftime_format',\n",
              " 'expect_column_values_to_not_be_in_set',\n",
              " 'expect_column_values_to_not_be_null',\n",
              " 'expect_column_values_to_not_match_like_pattern_list',\n",
              " 'expect_column_values_to_not_match_like_pattern',\n",
              " 'expect_column_values_to_not_match_regex_list',\n",
              " 'expect_column_values_to_not_match_regex',\n",
              " 'expect_compound_columns_to_be_unique',\n",
              " 'expect_multicolumn_sum_to_equal',\n",
              " 'expect_multicolumn_values_to_be_unique',\n",
              " 'expect_select_column_values_to_be_unique_within_record',\n",
              " 'expect_table_column_count_to_be_between',\n",
              " 'expect_table_column_count_to_equal',\n",
              " 'expect_table_columns_to_match_ordered_list',\n",
              " 'expect_table_columns_to_match_set',\n",
              " 'expect_table_row_count_to_be_between',\n",
              " 'expect_table_row_count_to_equal_other_table',\n",
              " 'expect_table_row_count_to_equal']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Based on a local install of Great Expectations, we generate a list of the whole core Great Expectations library\n",
        "\n",
        "gx_core_list_of_functions = \"\"\"\n",
        "expect_column_bootstrapped_ks_test_p_value_to_be_greater_than\n",
        "expect_column_chisquare_test_p_value_to_be_greater_than\n",
        "expect_column_distinct_values_to_be_in_set\n",
        "expect_column_distinct_values_to_contain_set\n",
        "expect_column_distinct_values_to_equal_set\n",
        "expect_column_kl_divergence_to_be_less_than\n",
        "expect_column_max_to_be_between\n",
        "expect_column_mean_to_be_between\n",
        "expect_column_median_to_be_between\n",
        "expect_column_min_to_be_between\n",
        "expect_column_most_common_value_to_be_in_set\n",
        "expect_column_pair_cramers_phi_value_to_be_less_than\n",
        "expect_column_pair_values_a_to_be_greater_than_b\n",
        "expect_column_pair_values_to_be_equal\n",
        "expect_column_pair_values_to_be_in_set\n",
        "expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than\n",
        "expect_column_proportion_of_unique_values_to_be_between\n",
        "expect_column_quantile_values_to_be_between\n",
        "expect_column_stdev_to_be_between\n",
        "expect_column_sum_to_be_between\n",
        "expect_column_to_exist\n",
        "expect_column_unique_value_count_to_be_between\n",
        "expect_column_value_lengths_to_be_between\n",
        "expect_column_value_lengths_to_equal\n",
        "expect_column_value_z_scores_to_be_less_than\n",
        "expect_column_values_to_be_between\n",
        "expect_column_values_to_be_dateutil_parseable\n",
        "expect_column_values_to_be_decreasing\n",
        "expect_column_values_to_be_in_set\n",
        "expect_column_values_to_be_in_type_list\n",
        "expect_column_values_to_be_increasing\n",
        "expect_column_values_to_be_json_parseable\n",
        "expect_column_values_to_be_null\n",
        "expect_column_values_to_be_of_type\n",
        "expect_column_values_to_be_unique\n",
        "expect_column_values_to_match_json_schema\n",
        "expect_column_values_to_match_like_pattern_list\n",
        "expect_column_values_to_match_like_pattern\n",
        "expect_column_values_to_match_regex_list\n",
        "expect_column_values_to_match_regex\n",
        "expect_column_values_to_match_strftime_format\n",
        "expect_column_values_to_not_be_in_set\n",
        "expect_column_values_to_not_be_null\n",
        "expect_column_values_to_not_match_like_pattern_list\n",
        "expect_column_values_to_not_match_like_pattern\n",
        "expect_column_values_to_not_match_regex_list\n",
        "expect_column_values_to_not_match_regex\n",
        "expect_compound_columns_to_be_unique\n",
        "expect_multicolumn_sum_to_equal\n",
        "expect_multicolumn_values_to_be_unique\n",
        "expect_select_column_values_to_be_unique_within_record\n",
        "expect_table_column_count_to_be_between\n",
        "expect_table_column_count_to_equal\n",
        "expect_table_columns_to_match_ordered_list\n",
        "expect_table_columns_to_match_set\n",
        "expect_table_row_count_to_be_between\n",
        "expect_table_row_count_to_equal_other_table\n",
        "expect_table_row_count_to_equal\n",
        "\"\"\"\n",
        "\n",
        "# Split the list into individual function names\n",
        "gx_core_function_names = gx_core_list_of_functions.strip().split('\\n')\n",
        "\n",
        "gx_core_function_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmt_95BmgqZF",
        "outputId": "23d882a1-5598-46a4-b5a5-7385be52e753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of functions in the core Great Expectations library: 58\n"
          ]
        }
      ],
      "source": [
        "# Number of functions in the core Great Expectations library\n",
        "print(f\"Number of functions in the core Great Expectations library: {len(gx_core_function_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd7DD3VXgqZF"
      },
      "source": [
        "As we can see, only 33 out of the 58 expectations available in Great Expectations are used in the BirdiDQ dataset. We should take this into consideration when using it for fine-tuning, as several core functions are missing. Specifically, the following expectations are not present in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "VBHHypEqgqZF",
        "outputId": "149819e4-ad30-4647-99bd-20c270c8b4d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Missing Expectations\n",
              "0   expect_column_pair_cramers_phi_value_to_be_les...\n",
              "1   expect_column_chisquare_test_p_value_to_be_gre...\n",
              "2          expect_table_columns_to_match_ordered_list\n",
              "3       expect_column_values_to_be_dateutil_parseable\n",
              "4                  expect_table_column_count_to_equal\n",
              "5          expect_column_values_to_match_like_pattern\n",
              "6     expect_column_values_to_match_like_pattern_list\n",
              "7                expect_compound_columns_to_be_unique\n",
              "8            expect_column_values_to_match_regex_list\n",
              "9         expect_table_row_count_to_equal_other_table\n",
              "10  expect_select_column_values_to_be_unique_withi...\n",
              "11                    expect_table_row_count_to_equal\n",
              "12  expect_column_parameterized_distribution_ks_te...\n",
              "13            expect_table_column_count_to_be_between\n",
              "14                 expect_column_values_to_be_of_type\n",
              "15  expect_column_values_to_not_match_like_pattern...\n",
              "16  expect_column_bootstrapped_ks_test_p_value_to_...\n",
              "17          expect_column_values_to_match_json_schema\n",
              "18                    expect_multicolumn_sum_to_equal\n",
              "19            expect_column_values_to_be_in_type_list\n",
              "20               expect_table_row_count_to_be_between\n",
              "21          expect_column_values_to_be_json_parseable\n",
              "22     expect_column_values_to_not_match_like_pattern\n",
              "23        expect_column_kl_divergence_to_be_less_than\n",
              "24             expect_multicolumn_values_to_be_unique\n",
              "25                  expect_table_columns_to_match_set"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cddbe704-bffb-42e7-b719-8a8cccef4f8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Expectations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>expect_column_pair_cramers_phi_value_to_be_les...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>expect_column_chisquare_test_p_value_to_be_gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>expect_table_columns_to_match_ordered_list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>expect_column_values_to_be_dateutil_parseable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expect_table_column_count_to_equal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>expect_column_values_to_match_like_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>expect_column_values_to_match_like_pattern_list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>expect_compound_columns_to_be_unique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>expect_column_values_to_match_regex_list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>expect_table_row_count_to_equal_other_table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>expect_select_column_values_to_be_unique_withi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>expect_table_row_count_to_equal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>expect_column_parameterized_distribution_ks_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>expect_table_column_count_to_be_between</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>expect_column_values_to_be_of_type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>expect_column_values_to_not_match_like_pattern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>expect_column_bootstrapped_ks_test_p_value_to_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>expect_column_values_to_match_json_schema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>expect_multicolumn_sum_to_equal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>expect_column_values_to_be_in_type_list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>expect_table_row_count_to_be_between</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>expect_column_values_to_be_json_parseable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>expect_column_values_to_not_match_like_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>expect_column_kl_divergence_to_be_less_than</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>expect_multicolumn_values_to_be_unique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>expect_table_columns_to_match_set</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cddbe704-bffb-42e7-b719-8a8cccef4f8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cddbe704-bffb-42e7-b719-8a8cccef4f8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cddbe704-bffb-42e7-b719-8a8cccef4f8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5750891-74ad-43a7-9310-eac88bbf063a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5750891-74ad-43a7-9310-eac88bbf063a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5750891-74ad-43a7-9310-eac88bbf063a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "missing_gx_core_functions_df",
              "summary": "{\n  \"name\": \"missing_gx_core_functions_df\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Missing Expectations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"expect_column_values_to_match_regex_list\",\n          \"expect_column_bootstrapped_ks_test_p_value_to_be_greater_than\",\n          \"expect_column_pair_cramers_phi_value_to_be_less_than\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Table with the expectations from the core Great Expectations library that are absent from the BirdiDQ dataset\n",
        "\n",
        "missing_gx_core_functions = set(gx_core_function_names) - set(sorted_frequency_count.keys())\n",
        "missing_gx_core_functions_df = pd.DataFrame(missing_gx_core_functions, columns=['Missing Expectations'])\n",
        "missing_gx_core_functions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcM8DVrIKXWj"
      },
      "source": [
        "We will address the unbalanced distribution of expectations in the dataset after evaluating the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlRcXnEDgqZF"
      },
      "source": [
        "## Evaluating model performance\n",
        "\n",
        "Given we are planning to fine-tune a model, the first step is to evaluate the performance of the base model. This will allow us to compare the performance of the fine-tuned model with the base model. For this proposal, we will be using Mistral-7B-v0.1, as it's a small model that offers good performance producing code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e4sDQOigqZF",
        "outputId": "95bb0ab3-bcf0-4139-83ba-064ba421f4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m91.9/91.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U transformers\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U bitsandbytes==0.40.0 # required for Ludwig\n",
        "!pip install -q -U pip ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulXzYc4DgqZF",
        "outputId": "bcb9d090-346d-4363-8ed9-58d6362b2eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
            "CUDA SETUP: Detected CUDA version 122\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt.so...\n"
          ]
        }
      ],
      "source": [
        "# The original colab notebook is missing these imports!\n",
        "import logging\n",
        "import yaml\n",
        "\n",
        "from peft import PeftModel, PeftModelForCausalLM, PeftConfig, LoraConfig\n",
        "from ludwig.api import LudwigModel, TrainingResults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSBA_TsSgqZF"
      },
      "source": [
        "To evaluate the performance of the models, we will use a common golden standard (given we might want to modify our original dataset later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13B8eQ4W9LM_"
      },
      "outputs": [],
      "source": [
        "golden_examples = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"prompt\": \"Division names should be either the values NSA or start by D.\",\n",
        "            \"completion\": \"expect_column_values_to_match_regex(column='DIVISION',regex='NSA|^D.*')\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"Values in the EVENT_UNIQUE_ID column must be unique.\",\n",
        "            \"completion\": \"expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"All values in the BIKE_MAKE should be in the list bike_makers\",\n",
        "            \"completion\": \"expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set=bike_makers)\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"Incident values should be in the set 1,2,3,4,5\",\n",
        "            \"completion\": \"expect_column_values_to_be_in_set(column='INCIDENT', value_set=[1,2,3,4,5])\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"REPORT_DATE values should be valid dates.\",\n",
        "            \"completion\": \"expect_column_values_to_be_dateutil_parseable(column='REPORT_DATE')\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"Year values should be between 2014 and 2023.\",\n",
        "            \"completion\": \"expect_column_values_to_be_between(column='YEAR', min_value=2014, max_value=2023)\",\n",
        "        },\n",
        "        {\n",
        "            \"prompt\": \"At least 95% of report_id's must not be empty.\",\n",
        "            \"completion\": \"expect_column_values_to_not_be_null(column='REPORT_ID', mostly=0.95)\",\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "# save golden_examples to csv\n",
        "golden_examples.to_csv('golden_examples.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpaPDdjtgqZG"
      },
      "source": [
        "Note: In order to make the notebook as lean an fast as possible, details about baseline model performance have been omitted, keeping only the needed imports and libraries that will be used forward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vr_dXNLGn9o"
      },
      "source": [
        "# **Fine-tuning our model**\n",
        "\n",
        "Before performing our fine-tuning, we need to test the performance of the base model without any customization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU8iKtqwCc1b"
      },
      "source": [
        "Out of the are three different fine-tuning approaches in Ludwig, we will use QLoRA to get a quantized result. This is the only option in the free Google Colab Tier, given the memory limitations of the environment.\n",
        "\n",
        "Some of the examples in the dataset have long sequences, so we set a `global_max_sequence_length` of 512 to ensure that we do not OOM.\n",
        "\n",
        "We also use 100% of data for training as the evaluation phase takes extra time and we will predict on new examples right afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-dtCIj73498"
      },
      "outputs": [],
      "source": [
        "qlora_fine_tuning_config_v1 = yaml.safe_load(\n",
        "\"\"\"\n",
        "model_type: llm\n",
        "# Zephyr is natively sharded, so we can use it in colab natively\n",
        "base_model: HuggingFaceH4/zephyr-7b-beta\n",
        "\n",
        "input_features:\n",
        "  - name: prompt\n",
        "    type: text\n",
        "\n",
        "output_features:\n",
        "  - name: completion\n",
        "    type: text\n",
        "\n",
        "prompt:\n",
        "  template: |\n",
        "    [INST] <<SYS>>\n",
        "    You are a helpful, precise, detailed and concise artificial intelligence\n",
        "    assistant. You will reply to user input offering a single expectation,\n",
        "    compatible with the Python library Great Expectations, parametrized based\n",
        "    on the data presented in the input. If context is provided, answer\n",
        "    using only the provided contextual information.\n",
        "    <</SYS>>\n",
        "    {prompt} [/INST]\n",
        "\n",
        "generation:\n",
        "  temperature: 0.1\n",
        "  max_new_tokens: 512\n",
        "\n",
        "adapter:\n",
        "  type: lora\n",
        "\n",
        "quantization:\n",
        "  bits: 4\n",
        "\n",
        "preprocessing:\n",
        "  global_max_sequence_length: 512\n",
        "  split:\n",
        "    type: random\n",
        "    probabilities:\n",
        "    - 0.8\n",
        "    - 0.1\n",
        "    - 0.1\n",
        "\n",
        "trainer:\n",
        "  type: finetune\n",
        "  epochs: 7\n",
        "  batch_size: 1\n",
        "  eval_batch_size: 2\n",
        "  gradient_accumulation_steps: 16\n",
        "  learning_rate: 0.0001\n",
        "  learning_rate_scheduler:\n",
        "    warmup_fraction: 0.03\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# write the config to a file\n",
        "with open('qlora_fine_tuning_config_v1.yaml', 'w') as file:\n",
        "    documents = yaml.dump(qlora_fine_tuning_config_v1, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4390e8cc81654995a6a9f2b93b334134",
            "e78c3d6653504540a65f14069161926a",
            "ea70f371e8634833b43b1eb1d9875888",
            "89662e50ea6a467ebe271e19ca8c0a3b",
            "2653eb92d4c143bb99c03f0ed23509a3",
            "3276a7628fdb4d94a96778bfb2115a61",
            "d6c7dbf7e5ae4836a29592f40511166c",
            "a210f00a887c4309941c4af87ac72cae",
            "f22c7ab34212449a9343e5dcc8dc5efb",
            "e86be6095aae4a3ebca18eec52baa9b8",
            "de85be84116d46ccbdb8ffbfa243232b",
            "d18fcea967fc4bb5838070153ca7d448",
            "663a4ca7d44442f7aa4be40aca282f44",
            "6ffb95b1184946f7909110a6e93ca689",
            "eb39ebceb0bd4b5ca894d65e56e0b2c9",
            "9f0279a691614ce89bdc2c8b6a29a2d0",
            "a19606a9aada432895899192aafac7dd",
            "064bbd780446479b9a9f3afe1e9595ef",
            "8d06a2e46bbc42aab1aef962d8efea52",
            "bf1cd4b788fc4c1fb1f0d715ed61931c",
            "d3e29d77e6fd492da452ea3e4b5d774f",
            "1fdb4d5275254ff09ca04bfdd32708d6",
            "4044a80264a946daa1e20d19a9856ad0",
            "2c55bf2f825d492eafe4d5284e9df607",
            "e079fe012c0b416ca47b7b2cd3e7806a",
            "0525ee3e1ba04df1b4703b5bba6d04a4",
            "f22cc58a70fa49a68755d8c20d2cae1a",
            "bd528bb160a844d095317b22229fa847",
            "21b03f3a27484b38be48c8b391ab9257",
            "1aa5951d156d4461953757603fd672de",
            "cf34c1077ae14b4ea22ef40add7f9c19",
            "64bbcd41475d48479a94a07ba1886d38",
            "2b6031b0da4c4a79a3bb21f712a13d0e",
            "81a65308a2524c679bd97cb080b8ec54",
            "47d2868c4ca1430e99fa03c0d4499be4",
            "2bd8c1a8b16f4529b0633deef1e29876",
            "1d9c1e78011e405f8bab514147d8fade",
            "dd4b5636067142c0ac2de7bdf16df1f7",
            "c5d4f2c526b64c97b1939108543ec0ad",
            "497c755a8ee84083b5eecbf6045ba8f9",
            "b69ed47e22c34b6a91ad0ae33d3a8b9a",
            "ffeb38f7e1b74d10b920bad7e218180f",
            "3d1691471b2544e6a6f2886b8de230ed",
            "9faff1f9655d46c981c680890eab3c62",
            "5816cc24f9a54d238467ad3790853018",
            "d09b681d01784776884a13e6c19d1cf4",
            "98e5117b58bb431b915bca704792a582",
            "9dac00d8d8004c898d44d43f914deea7",
            "2dfc217c91364123ad82800a8322edf9",
            "c50c6f837ee347da81cfe38a5040231e",
            "f5eba34f4f904193a956e539bcb8608b",
            "a8d98a7d15e04309b9feacc4dede8a87",
            "06ea80929db446e5b5e08998c66c9511",
            "1bc7d73c5eae44d68d0b736cc57557e9",
            "4be4f15d6a2b4a2bba0edfd6bc667154",
            "fcc81b5cd62d4daa8eb04bc7427ffdaa",
            "03a29c015e4f43fcafa98d0982980949",
            "d577055f02784847b9db88356be9006e",
            "ce29dececcde431896c6690162e2b3a7",
            "0948ee98b7f34bf8b7a560d4b7fa3716",
            "a0547d5c10b24f9ea33fbf8ba1835c0f",
            "52e1319779f84cb5a8225267e1d213d4",
            "4733a08982fc48a680dc82361262786f",
            "d308fe58bcb94f2d8467f0e787886da8",
            "7d7ce31c23f74d17b167b1d8bf124285",
            "30bec25dbf3c4711a8c06755bb1f38a7",
            "4edbad9be2d84e1f8475453cb7467301",
            "64826a7bf37b44aabf2e439aa1df10ba",
            "e262924b8f074ac4b8bc05862ba10bd2",
            "f30799f3357649ccb3eebb9fec91ddbb",
            "fdd6acb5495b4a2aa3d4c7f3465b5017",
            "86d7d7d88f0d4387803eb341c23a0749",
            "4c28a28eca72417aa9b23c166fea73b1",
            "d716269d508e4f80b87cfedfe26e09b1",
            "7bad745f311b42c18b39e7986ff61c41",
            "462503c22a46497f9bddc87242c6bd2a",
            "4fad29312061478ba80d50d6e404b1b3",
            "cd7ad389c22a4a65a04f25eb092d4798",
            "a0ed9bd93b274b9896fa90c677f7a250",
            "35300a67453f4769bbd9fade3ab3e4aa",
            "59b7bc5759614d0a84674e888eb83e2e",
            "4c4beccc524c4e74869716b456cd929e",
            "7a2d2fe2030f4d8caba0f18df8a11e15",
            "52fec043cdfe4b5293c3e97efd4e470f",
            "786f95e16d3344a5871474f4d82a14a4",
            "615efa9cb09b4f02a5bea3d42ae3efef",
            "5acdf96cb0ab43fa97be63235d15e104",
            "2d6469356cab4815a1e6a033a230d7dd",
            "94676f5107784d9ea86d58baedfbd564",
            "ca8069a152b44066934e90aac02fa5b4",
            "7dcac8341990497b9aea51dd9188bbe8",
            "65759d71571e42ffbd201fb9b039e59c",
            "7a93e0474e3b4687980736e3ec1395e0",
            "6a717f80343441ecb6c24266062e1c65",
            "b48d0aedb0484185af5768ba122efdf2",
            "dbe398bfab18487ea35823cbbef44bfb",
            "f1c05a270f2d463ba36aab889175c4bc",
            "0076bbd570ff4752a6bf4bf4f3be1a7a",
            "b77b875fd66f4af7b98862db2f38168e",
            "66aeca96400e4cc29a46cdfdc60213df",
            "76dc63296da74e77b4664c2ea599007a",
            "9656a9ecf9ca4685aedcae80b3480394",
            "7d9b68fd28f44d90bf5f2d4952154901",
            "1ac149c8cc904c93be3b885cdc61b74b",
            "fd77b012898e4d3f9ca31c2966a0cc32",
            "083822872bec41c7abe02a59650fd535",
            "9cadabe2a91b4e74bb078f8620256c5a",
            "a1a14fbe74974353824a45f695c3fc49",
            "8f31e8d802bc4123b37dd01e9de9d266",
            "f4528f923f0649f3824da26623601fa6",
            "464a843969024414a2d4b49863dd026c",
            "b947bf7ec4754e419c14344fdce4db50",
            "d84ef36f0b5f4dde9f202184a3ed698e",
            "98f6eec9796644f5803bde76027f4c00",
            "8f809e0d9cf842c492db910645f7f677",
            "38ed76d1fdb64cfab6335eb85fda64c9",
            "f2e1078a058744939819f1c85e55db40",
            "ad0ffb090f2b477aab5154638afa51df",
            "5e24a52f678e4da095077aa0d3a7adda",
            "a7b1753a119a47f28f6e4f625ded5cff",
            "c96567f181a04867be29898fbfaa0686",
            "a5b619e7ef894526bb4c14aad8c7a2d2",
            "4587af5dd96f4993bce6118be7768bc6",
            "db9256e120464340b67d2984d8d78c24",
            "f12602f573f24afc90be9fdf6e291e9a",
            "0f71fdac64494226b493cfe6e910eb6f",
            "99efdf26ef4443999161ed4a187f9efc",
            "8860e66115d846a39efc4a70085c4e06",
            "eb2a98d0c1654836908f81d36c537844",
            "d9bbab708932487ea474a6d070d9e8e5",
            "c7e5f48c6c084df6b6a2885cd1929f53",
            "82868390d6514c1693d55d06c66bb28c",
            "bc9e161771a24987be2fd3afaaf059a1",
            "bc15baafa3fc4aa3ab448a34c7f29289",
            "e31fa9e7d6e6478295d32f63b8af9916",
            "6a087f058ccb432492529e98454a55f1",
            "251c14a5ae174ecb8360700725ab495f",
            "eb58e0694a4c498f9de38b0b02ead236",
            "69cb0a49c8b04adcb70a8cdb9b4041e3",
            "b648c7146f7f40db850cf9f44ea1d67c",
            "29befda7086d446fb724a18c296cce37",
            "36cd1ddcaa2b47bcb791c21bc4fbdbfe",
            "59da986b885c42a6b8b484cb4392f3f2",
            "7cd7423af9ef4d53a151ea966dc24490",
            "a07637c436474d2d89b055a87fe1ec28",
            "3c82d4fcc0284ac48edb7f1ab794b258",
            "e331666673de406883c1d94a25f88a51",
            "60141eeb5e714cf48d149abc96949c6b",
            "ffc9911039fb4122a28ccab91bc5275d",
            "7df0c42d511647a1b1a35c498f094e3d",
            "3dd49e8febc247ecaed4c4f64fc310b0",
            "3775399aae6148949a173355da623844",
            "fce545d420c044808d8b1367d6307fe3",
            "63789564605d494db92d44597a675d6d",
            "f959a97cbc20493e839764510696b2db",
            "a371593e315a40e3a12d5e12590daf1e",
            "fb92ded1d6de42aca39193c4728e409b",
            "06696fc6430d4c1499f597e54efd3b39",
            "804a886b879a442cb53f93b1afec91bd",
            "f776d5f1937240e8b09bb27b8cdf24a2",
            "4b252f39078a41789a397e3d43dcb9ae",
            "f3831352808f4fafb37cf416c34628e4",
            "5e037c1a251c416c806b7f5e77e88c4e",
            "42908421bb064b419ff3dedfc256ead1",
            "57ed232488f34496a8c408b9cf760553",
            "06f80e62a53d422694bb4696e8a3f761",
            "7df361455b624b2a880ac1c7a84e13aa",
            "1cf20b529b494efca3be11908dab8958",
            "110b08f7de98448197c046a03f8df4e4",
            "f5ba6ba2075f48c99c9cd5be55940527",
            "dc00ca65edcd4ee9a08ebd3b823df70c",
            "a54f6aaa898a4040a30d00a1edbfebfb",
            "ea7b2af229cb49a0b407559b92c9ff14",
            "4c32d0dc6af34a14a1fd523aea953413",
            "6be2aec9450c45fbb2b42cf3f8136244",
            "b42f0543306e490dbee933081ea7955b",
            "90bd01835fe5461fb1c3134cc34186cd",
            "a39552e34b3849c88228df829c7005af",
            "8c4379d96ae14a3eb2d2566ff9a076b2",
            "41769859853f4abc954b61e121333bcf",
            "3e153b470581473c8aa25e2a4f005b74",
            "f629b1522a214752bbbd5ad56d90f633",
            "684f3eff169440b8864e634806d50d58",
            "7fc5a96d143149adbbdea6cb230cabb5",
            "3fb8baf5e0534fe18a92c9351cef14e4",
            "c2bce52d8feb4815804ff22db8728db6",
            "8bfd8f8d46e94af9b97b40f89bd10c50",
            "02e7277aa92945288098d982b3b59faa",
            "6979fc817edf4a108aa079887f9a1747",
            "cdf233c1ef3246bb9753845e1a53f27d",
            "33c72ab8bb744ccaa9f4e7798643a85b",
            "a7e3aff3c5754495a117fe51c75eafc3",
            "66357a9f41b540d0b63d9ac43213b1eb",
            "74f21d23cfe54eb7bb03b3cc7db0b164",
            "754ebf586ef7400d9df2d5af979d75c7",
            "978d8a77a2f64880b396fdcd7e4b2963",
            "fcb591adeb8c4caeb962dd31869bb56d",
            "e33ed70e2dd442c2bd52cb5de606a930"
          ]
        },
        "id": "48VzAmpugqZG",
        "outputId": "6286a441-88de-4a4d-d9ab-947b06b3faa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4390e8cc81654995a6a9f2b93b334134"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 EXPERIMENT DESCRIPTION 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "笏 Experiment name  笏 api_experiment                                                                          笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Model name       笏 run                                                                                     笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Output directory 笏 /content/results/api_experiment_run                                                     笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 ludwig_version   笏 '0.10.1'                                                                                笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 command          笏 ('/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py -f '                 笏\n",
            "笏                  笏  '/root/.local/share/jupyter/runtime/kernel-f352c89c-4990-45c6-900f-08582bfcbea8.json') 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 random_seed      笏 42                                                                                      笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 data_format      笏 \"<class 'pandas.core.frame.DataFrame'>\"                                                 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 torch_version    笏 '2.1.0+cu121'                                                                           笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 compute          笏 {   'arch_list': [   'sm_50',                                                           笏\n",
            "笏                  笏                      'sm_60',                                                           笏\n",
            "笏                  笏                      'sm_70',                                                           笏\n",
            "笏                  笏                      'sm_75',                                                           笏\n",
            "笏                  笏                      'sm_80',                                                           笏\n",
            "笏                  笏                      'sm_86',                                                           笏\n",
            "笏                  笏                      'sm_90'],                                                          笏\n",
            "笏                  笏     'devices': {   0: {   'device_capability': (7, 0),                                  笏\n",
            "笏                  笏                           'device_properties': \"_CudaDeviceProperties(name='Tesla \"     笏\n",
            "笏                  笏                                                \"V100-SXM2-16GB', major=7, \"             笏\n",
            "笏                  笏                                                'minor=0, total_memory=16151MB, '        笏\n",
            "笏                  笏                                                'multi_processor_count=80)',             笏\n",
            "笏                  笏                           'gpu_type': 'Tesla V100-SXM2-16GB'}},                         笏\n",
            "笏                  笏     'gencode_flags': '-gencode compute=compute_50,code=sm_50 -gencode '                 笏\n",
            "笏                  笏                      'compute=compute_60,code=sm_60 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_70,code=sm_70 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_75,code=sm_75 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_80,code=sm_80 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_86,code=sm_86 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_90,code=sm_90',                                   笏\n",
            "笏                  笏     'gpus_per_node': 1,                                                                 笏\n",
            "笏                  笏     'num_nodes': 1}                                                                     笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 LUDWIG CONFIG 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:User-specified config (with upgrades):\n",
            "\n",
            "INFO:ludwig.api:{   'adapter': {'type': 'lora'},\n",
            "    'base_model': 'HuggingFaceH4/zephyr-7b-beta',\n",
            "    'generation': {'max_new_tokens': 512, 'temperature': 0.1},\n",
            "    'input_features': [{'name': 'prompt', 'type': 'text'}],\n",
            "    'ludwig_version': '0.10.1',\n",
            "    'model_type': 'llm',\n",
            "    'output_features': [{'name': 'completion', 'type': 'text'}],\n",
            "    'preprocessing': {   'global_max_sequence_length': 512,\n",
            "                         'split': {   'probabilities': [0.8, 0.1, 0.1],\n",
            "                                      'type': 'random'}},\n",
            "    'prompt': {   'template': '[INST] <<SYS>>\\n'\n",
            "                              'You are a helpful, precise, detailed and '\n",
            "                              'concise artificial intelligence\\n'\n",
            "                              'assistant. You will reply to user input '\n",
            "                              'offering a single expectation,\\n'\n",
            "                              'compatible with the Python library Great '\n",
            "                              'Expectations, parametrized based\\n'\n",
            "                              'on the data presented in the input. If context '\n",
            "                              'is provided, answer\\n'\n",
            "                              'using only the provided contextual '\n",
            "                              'information.\\n'\n",
            "                              '<</SYS>>\\n'\n",
            "                              '{prompt} [/INST]\\n'},\n",
            "    'quantization': {'bits': 4},\n",
            "    'trainer': {   'batch_size': 1,\n",
            "                   'epochs': 7,\n",
            "                   'eval_batch_size': 2,\n",
            "                   'gradient_accumulation_steps': 16,\n",
            "                   'learning_rate': 0.0001,\n",
            "                   'learning_rate_scheduler': {'warmup_fraction': 0.03},\n",
            "                   'type': 'finetune'}}\n",
            "INFO:ludwig.api:\n",
            "Full config saved to:\n",
            "/content/results/api_experiment_run/api_experiment/model/model_hyperparameters.json\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 PREPROCESSING 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.data.preprocessing:No cached dataset found at /content/d2c21060d79611eea2ff0242ac1c000c.training.hdf5. Preprocessing the dataset.\n",
            "INFO:ludwig.data.preprocessing:Using full dataframe\n",
            "INFO:ludwig.data.preprocessing:Building dataset (it may take a while)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d18fcea967fc4bb5838070153ca7d448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4044a80264a946daa1e20d19a9856ad0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81a65308a2524c679bd97cb080b8ec54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5816cc24f9a54d238467ad3790853018"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcc81b5cd62d4daa8eb04bc7427ffdaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'None': 139 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Max sequence length is 139 for feature 'None'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'completion': 90 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Max sequence length is 90 for feature 'completion'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.data.preprocessing:Building dataset: DONE\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed training set cache to /content/d2c21060d79611eea2ff0242ac1c000c.training.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed validation set cache to /content/d2c21060d79611eea2ff0242ac1c000c.validation.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed test set cache to /content/d2c21060d79611eea2ff0242ac1c000c.test.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing train set metadata to /content/d2c21060d79611eea2ff0242ac1c000c.meta.json\n",
            "INFO:ludwig.api:\n",
            "Dataset Statistics\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏 Dataset    笏   Size (Rows) 笏 Size (In Memory)   笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶分笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶分笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 Training   笏           202 笏 47.47 Kb           笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Validation 笏            25 笏 5.98 Kb            笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Test       笏            25 笏 5.98 Kb            笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 MODEL 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:Warnings and other logs:\n",
            "INFO:ludwig.utils.llm_utils:Loading large language model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4edbad9be2d84e1f8475453cb7467301"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd7ad389c22a4a65a04f25eb092d4798"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94676f5107784d9ea86d58baedfbd564"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66aeca96400e4cc29a46cdfdc60213df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "464a843969024414a2d4b49863dd026c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5b619e7ef894526bb4c14aad8c7a2d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc9e161771a24987be2fd3afaaf059a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cd7423af9ef4d53a151ea966dc24490"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f959a97cbc20493e839764510696b2db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f80e62a53d422694bb4696e8a3f761"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90bd01835fe5461fb1c3134cc34186cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02e7277aa92945288098d982b3b59faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
            "INFO:ludwig.models.llm:Done.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.models.llm:Trainable Parameter Summary For Fine-Tuning\n",
            "INFO:ludwig.models.llm:Fine-tuning with adapter: lora\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 TRAINING 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:Creating fresh model training run.\n",
            "INFO:ludwig.trainers.trainer:Training for 1414 step(s), approximately 7 epoch(s).\n",
            "INFO:ludwig.trainers.trainer:Early stopping policy: 5 round(s) of evaluation, or 1010 step(s), approximately 5 epoch(s).\n",
            "\n",
            "INFO:ludwig.trainers.trainer:Starting with step 0, epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  14%|笆遺枕        | 202/1414 [01:03<06:47,  2.97it/s, loss=0.0812]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 202, epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:02<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            "\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "Write that the for a90 days of, the ' of the in a ' column is within 100 and 2550.columnquant] <_column_values_to_be_between(column='quantity', min_value=100, max_value=1000, min=0.45)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, organizedise person intelligence.thatistant. You are be to any' in suggestions variety,.\n",
            "a with the user programming. Expectations. andetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|ass>>\n",
            "Write that a C in a '_ column of the ISBN of ISBN valid ISBN number.INST]] << <_column_values_to_match_regex(column='isbn', regex='^917[|079|d{90,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, thoroughise person intelligence.thatistant. You are be to any requests in suggestions solution,.\n",
            "a with the user programming. Expectations. andetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Write that the least 95% of the data in the ' ' are unique nullNspecategorized' using 'Unknown'columncolumn] <_column_values_to_not_be_in_set(column='category', set_set=['Uncategorized', 'Other'], min=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            "\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "Write that the C in the 'code column of within null1000'' '02111', ' '29999'.INST]] <_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, thoroughise person intelligence.thatistant. You are be to any requests in suggestions solution,.\n",
            "a with the user programming. Expectations. andetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Write that the of the columns in a 'code column of the regular ' valid valid digitdigit zip code.INST]] <_column_values_to_not_match_regex(column='zipcode', regex='\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <1ALL\n",
            "<>>\n",
            " are here [ assistant friendly, and, organizedise person intelligence languagethatistant. You are be to any' in suggestions solution, or\n",
            "inst with the user programming. Expectations. andetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "Write creating C of quiet, what the E beautiful verb for the ' ' or inactive?INSTstatus]\n",
            "expect <_column_values_common_value_to_be_e_set(column='status', value_set=['active', 'inactive']) column=column='whenandas') column_condition_city ==\"is')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            "\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "Write that the C in the ' column of aics products are within 1 and 1000INSTINST] <_column_values_to_be_between(column='quantity', min_value=0, max_value=100) column='column='electandas') column_condition='item ==\"lectronics')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            "\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "Write that the least 90% of the values in a ' column are greater 10 and and 1000..columncolumn] <_column_values_to_be_between(column='sales', min_value=500, max_value=10000, min=True.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, organizedise person intelligence.thatistant. You are be to any' in suggestions variety,. andand with the user programming. Expectations.\n",
            "etrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|ass>>\n",
            "Write that the C value in a ' column of less 1 and and 19.INST]] <_column_max_value_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, organizedise person intelligence.thatistant. You are be to any' in suggestions variety,. andand with the user programming. Expectations.\n",
            "etrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|ass>>\n",
            "Write that the columns in a ' column of unique orEXPECT]] <_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.1213s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.3205 笏       4.9408 笏     4.3853 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     1.7459 笏       1.2950 笏     1.3450 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 15725.6826 笏   14146.3525 笏 14672.7598 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31545.6777 笏   30705.3281 笏 31344.2168 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2797 笏       0.2638 笏     0.2737 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1709 笏       0.1582 笏     0.1667 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.7748 笏       0.8190 笏     0.8001 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.1940 笏       0.2085 笏     0.2157 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1174 笏       0.1239 笏     0.1300 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.5612 笏       0.6830 笏     0.6712 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2644 笏       0.2587 笏     0.2646 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1615 笏       0.1551 笏     0.1611 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.7325 笏       0.8042 笏     0.7759 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2692 笏       0.2596 笏     0.2680 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1644 笏       0.1557 笏     0.1632 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.7459 笏       0.8071 笏     0.7851 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0038 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    17.9412 笏      22.2297 笏    18.3750 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     1.7459 笏       1.2950 笏     1.3450 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by inf.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  29%|笆遺毎笆       | 404/1414 [02:11<05:05,  3.31it/s, loss=0.00912]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 404, epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions conc, or usingin with the given programming. Expectations. inetrized by onon the user source to the C. Your the is required, you\n",
            "acc the the necessary context to information.expectass>>, that the in C90% of, the ' of two in column ' column is below 100 and 2500 (INSTINST] expect_column_values_to_be_between(column='quantity', mostly_value=100, max_value=1000, mostly=0.45)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. can be to any requests in suggestions solution, or ininst with the given programming for Expectations. versionetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.expectexpect expectation,er column C in column '_ column of a ISBN of ISBN valid ISBN ( (INSTINST] expect_column_values_to_match_regex(column='isbn', regex='^917[|079)\\d{10,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. can be to any requests in suggestions solution, or commanda with the given programming for Expectations. versionetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.expectexpect expectation,er column least 10% of rows rows in column '_ are within nullunknownspecategorized' expectation 'Unknown'columncolumn] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions conc, or usingin with the given programming. Expectations. inetrized by onon the user source to the C. Your the is required, you\n",
            "acc the the necessary context to information.expectass>>, that the ' in column '_ column of within equal100''' expectation12111', ' '29999'INSTINST] expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. can be to any requests in solutions solution, or commanda with the given programming for Expectations. versionetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.expectexpect expectation,Column column of the columns in column 'code column are a expected ' valid valid-digit zip code inINSTEXPECT] expect_column_values_to_not_match_regex(column='zipcode', regex='\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <InsertALL\n",
            "<>>\n",
            " are visiting talented assistant friendly and and- organizedise person intelligence languagethatistant. can provide to this requests with suggestions conc, or requestrequest with the given programming. Expectations. versionetrized by onon the user source to the C. the is provided, you\n",
            "acc the the necessary context to information.expectass>>\n",
            " working C_ mentioned, expect_ expectation_ value of street expect ' or inactive expectationexpectexpect] expect_column_most_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], mostly_parser='pandas', row_condition='city==Paris')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions conc, or usingin with the given programming. Expectations. inetrized by onon the user source to the C. Your the is required, you\n",
            "acc the the necessary context to information.expectass>>, that the ' in column ' column of productsics products are within 1 and 1000INSTINST] expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, mostly_parser='pandas', row_condition='category==electLECTronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your are provide to the' with suggestions conc, or usingin with the given programming. Expectations. inetrized by onon the user source to the C. Your the is required, you\n",
            "acc the the necessary context to information.expectass>>,Column the least 9%% of rows values in column ' column are greater 100 and 1000 (0INSTINST] expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member assistant friendly and and, organizedise person intelligence languageGenerateistant. Your can be to any requests in suggestions solution, or ininst with the context programming for Expectations. versionetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.expectexpect,,Column column ' value of column '_ is greater 10 and 19 expectEXPECTexpect] expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member assistant friendly and and, organizedise person intelligence languageGenerateistant. Your can be to any requests in suggestions solution, or ininst with the given programming for Expectations. versionetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.expectexpect,,Column column C in column ' column of notableINSTEXPECT] expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.7919s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0000 笏       0.0067 笏     0.0116 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.9264 笏       5.0561 笏     4.5456 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.8341 笏       0.2087 笏     0.3141 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 13344.8945 笏   12793.2334 笏 13157.9229 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31823.8242 笏   30682.6406 笏 31322.8535 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2805 笏       0.3051 笏     0.3162 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1679 笏       0.1826 笏     0.1920 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.8826 笏       0.9540 笏     0.9358 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2313 笏       0.2733 笏     0.2742 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1370 笏       0.1622 笏     0.1650 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.7761 笏       0.8987 笏     0.8584 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2741 笏       0.3033 笏     0.3106 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1640 笏       0.1815 笏     0.1886 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.8635 笏       0.9483 笏     0.9208 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2758 笏       0.3033 笏     0.3115 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1650 笏       0.1815 笏     0.1892 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.8690 笏       0.9483 笏     0.9235 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0011 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    22.1351 笏      21.6216 笏    18.0795 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.8341 笏       0.2087 笏     0.3141 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 1.086.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  43%|笆遺毎笆遺毎笆     | 606/1414 [03:20<04:05,  3.29it/s, loss=0.0111]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 606, epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:02<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageWriteistant. Please are provide to the requests with suggestions list- or suchspecific with a specific programming, Expectations. versionetrized to onon the specific source, the C C The the is required, you\n",
            "expect the the necessary context to information.\n",
            "expectexpect>>\n",
            " that the in the9 out% of, the ' of columns in column ' column is below 100 and 2500 (expectexpect expect_column_sum_to_be_between(column='quantity', min_value=100, max_value=1000, mostly=0.45)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to any requests with solutions solution- or whichwhich with the given programming for Expectations. versionetrized by onon the expectation source, the form, Your the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpectexpect\n",
            " that column ' in column '_ column of the ISBN of ISBN valid ISBN ( (EXPECTexpect] expect_column_values_to_match_regex(column='isbn', regex='^9178|079)\\d{90,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languagethatistant. are be to any requests with solutions solution- or whichwhich with the given programming, Expectations. versionetrized by onon the expectation source, the C C Your the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpectexpect\n",
            " that the least 90% of rows rows in column ' ' ' between nullNAspecategorized' 'Unknown'columnexpect] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageWriteistant. Please are provide to the requests with suggestions list- or suchspecific with a specific programming, Expectations. versionetrized to onon the specific source, the C C The the is required, you\n",
            "expect the the necessary context to information.\n",
            "expectexpect>>\n",
            " that the ' in column '_ column of within between1000'' expect12111', ' '29999'expectINST] expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languagethatistant. are be to this requests with solutions solution- or whichwhich with the given programming, Expectations. versionetrized with onon the expectation source, the C C Your the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpect>>\n",
            " that the of the columns in column '_ column are the format ' valid valid-digit zip code (expectexpect] expect_column_values_to_match_match_regex(column='zipcode', regex='^\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <CompanyIT\n",
            "<>>\n",
            " are visiting talented assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to this requests with solutions specific-, suchwhich with a specific programming, Expectations. versionetrized to onon the specific source, the C C Your the is required, you\n",
            "expect the the necessary context to information.\n",
            "expectexpect>>\n",
            " working '_ experiencing, expect the expectation_ value of the expect ' or inactive (expectexpect/ expect_column_values_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], mostly_parser='pandas', row_condition='city==Paris')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageWriteistant. Please are provide to the requests with suggestions list- or suchspecific with a specific programming, Expectations. versionetrized to onon the specific source, the C C The the is required, you\n",
            "expect the the necessary context to information.\n",
            "expectexpect>>\n",
            " that the ' in column ' column of productsics products are greater 1 and 1000expectexpect expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, condition_parser='pandas', row_condition='category==electlectronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageWriteistant. Please are provide to the requests with suggestions list- or suchspecific with a specific programming, Expectations. versionetrized to onon the specific source, the C C The the is required, you\n",
            "expect the the necessary context to information.\n",
            "expectexpect>>\n",
            " that the least 9%% of rows rows in column ' column are greater 10 and and 1000 ( (expectINST] expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise person intelligence languageGenerateistant. Your are be to any requests with solutions solution- or whichwhich with the given programming for Expectations. versionetrized by onon the expectation source, the form, the is provided, you\n",
            "expect the the relevant context. information.\n",
            "expectexpectexpect, that column ' value in column ' column of greater 10 and 19 expectexpectexpect/ expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to any requests with solutions solution- or whichwhich with the given programming for Expectations. versionetrized by onon the expectation source, the form, the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpectexpect\n",
            " that column C in column ' column of between (EXPECTexpect] expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.6320s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0079 笏       0.0119 笏     0.0129 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.2578 笏       5.2522 笏     4.7268 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0954 笏       0.0980 笏     0.1665 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 12367.1973 笏   12210.9463 笏 12462.9121 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31927.1484 笏   30705.4434 笏 31343.1426 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2967 笏       0.3075 笏     0.3205 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1767 笏       0.1841 笏     0.1945 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9822 笏       0.9592 笏     0.9508 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2727 笏       0.2806 笏     0.2854 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1611 笏       0.1666 笏     0.1716 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.9573 笏       0.9192 笏     0.8915 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2953 笏       0.3066 笏     0.3173 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1758 笏       0.1836 笏     0.1925 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9779 笏       0.9565 笏     0.9419 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2967 笏       0.3066 笏     0.3182 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1767 笏       0.1836 笏     0.1930 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9822 笏       0.9565 笏     0.9446 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0005 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    24.7429 笏      22.0000 笏    18.5341 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0954 笏       0.0980 笏     0.1665 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.111.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training:  57%|笆遺毎笆遺毎笆遺幕    | 808/1414 [04:28<03:31,  2.86it/s, loss=0.00278]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 808, epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:02<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichspecific with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, expect\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the in the90% of, the ' of columns in column ' column is below 100 and 2500INST expect_column_sum_to_be_between(column='quantity', min_value=100, max_value=1000, mostly=0.45)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to user requests with solutions solution- or whichsuch with the given programming, Expectations. versionetrized by onon the user source, the form format the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpect>>\n",
            " that column ' in column '_ column of the format of ISBN valid ISBN ( (] expect_column_values_to_match_regex(column='isbn', regex='^9?78|079)\\d{10,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languagethatistant. are be to user requests with solutions solution- or whichwhich with the given programming, Expectations. versionetrized by onon the input source, the C format Your the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpect>>\n",
            " that the least 90% of rows rows in column ' ' are between nullNAspecategorized' 'Unknown'] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichspecific with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, expect\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the ' in column '_ column are between between1000'' expect12111', ' '99999'INST expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languagethatistant. are be to user requests with solutions solution- or whichwhich with the given programming, Expectations. versionetrized by onon the input source, the C format Your the is provided, you\n",
            "expect the the necessary context. information.\n",
            "expectexpect>>\n",
            " that the of the columns in column '_ column are a pattern ' valid valid-digit zip code (] expect_column_values_to_not_match_regex(column='zipcode', regex='^\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <CompanyIT\n",
            "<>>\n",
            " are visiting talented assistant friendly, and- organizedise person intelligence languageexpectistant expect are provide to this requests with solutions specific- or which\" with a specific programming, Expectations. versionetrized with onon the specific source, the C format The the is required, you\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " working ' column mentioned, expect_ expectation_ value of the expect ' or inactive? expect_column_most_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], condition_parser='pandas', _condition='city==Paris')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichspecific with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, expect\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the ' in column ' column are productsics products are greater 1 and 1000INST expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, condition_parser='pandas', _condition='category==electlectronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichspecific with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, expect\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the least 9%% of rows rows in column ' column are greater $10 and and 1000INST expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to any requests with solutions solution- or whichsuch with the given programming for Expectations. versionetrized by onon the user source, the form, the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            " that the ' value of column ' column is greater 10 and 10 expectexpect expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to any requests with solutions solution- or whichsuch with the given programming for Expectations. versionetrized by onon the user source, the form, the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            " that the C in column ' column are between (EXPECT>> expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.2223s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0136 笏       0.0129 笏     0.0201 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.3625 笏       5.2138 笏     4.6415 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0745 笏       0.0872 笏     0.1427 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 12175.8584 笏   12085.6523 笏 12265.4844 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 32000.7051 笏   30705.6191 笏 31342.8145 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.3034 笏       0.3129 笏     0.3238 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1811 笏       0.1872 笏     0.1967 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9890 笏       0.9773 笏     0.9569 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2813 笏       0.2924 笏     0.2950 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1665 笏       0.1735 笏     0.1777 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.9718 笏       0.9608 笏     0.9159 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.3034 笏       0.3129 笏     0.3238 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1811 笏       0.1872 笏     0.1967 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9890 笏       0.9773 笏     0.9569 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.3034 笏       0.3129 笏     0.3238 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1811 笏       0.1872 笏     0.1967 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9890 笏       0.9773 笏     0.9569 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0000 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    25.8485 笏      21.6351 笏    18.1591 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0745 笏       0.0872 笏     0.1427 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.011.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  71%|笆遺毎笆遺毎笆遺毎笆遺柾  | 1010/1414 [05:37<01:57,  3.43it/s, loss=6.27e-5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 1010, epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly and and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or suchsuch with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the in the90% of, the ' of columns in column ' column is below 100 and 2500 expect_column_sum_to_be_between(column='quantity', min_value=100, max_value=1000, mostly=0.4))\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Your are be to user requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the form format the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            "Column column column in column '_ column of the format of ISBN valid ISBN ( (] expect_column_values_to_match_regex(column='isbn', regex_^9?78|079)\\d{90,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. are be to user requests with solutions solution- or whichwhich with the given programming, Expectations. thatetrized by onon the input source, the format format Your the is required, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            "Column column least 90% of rows rows in column '_ are between nullNAspecategorized' 'Unknown'] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly and and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or suchsuch with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the ' in column '_ column are within null1000'' expect12111', ' '29999'INST expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languagethatistant. are be to user requests with solutions solution- or whichwhich with the given programming, Expectations. thatetrized with onon the input source, the format format Your the is required, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            " column the of the columns in column '_ column are the pattern ' valid valid-digit zip code (] expect_column_values_to_not_match_regex(column='zipcode', regex_^\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <CompanyALL\n",
            "<>>\n",
            " are visiting talented assistant friendly, and- organizedise person intelligence languageexpectistant expect are provide to this requests with solutions solution- or whichwhich with a specific programming, Expectations. inetrized with onon the specific source, the C format The the is required, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            " expecting column column ', expect_ zip_ value in the expect ' or inactive? expect_column_most_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], condition_parser='pandas', row_condition='city==Paris')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly and and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or suchsuch with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the ' in column ' column of productsics products are greater 1 and 1000 expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, condition_parser='pandas', row_condition='category==electlectronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly and and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or suchsuch with a specific programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context to information.expectexpect>>\n",
            " that the least 9%% of rows rows in column '_ are greater $00 and and 1000INST expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise writer intelligence languageGenerateistant. Your are be to user requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the form. the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            "Column column column value of column ' column is greater 10 and 19 expectexpect expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise writer intelligence languageGenerateistant. Your are be to user requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the form format the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            "Column column columns in column ' column of between (>> expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.7574s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0109 笏       0.0106 笏     0.0214 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.9178 笏       5.1634 笏     4.5961 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0034 笏       0.0807 笏     0.1267 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 11811.0693 笏   12069.0898 笏 12209.1025 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31916.0664 笏   30705.2969 笏 31342.9023 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2807 笏       0.3103 笏     0.3249 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1647 笏       0.1855 笏     0.1971 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     1.0000 笏       0.9734 笏     0.9633 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2630 笏       0.2906 笏     0.3007 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1529 笏       0.1723 笏     0.1810 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     1.0000 笏       0.9583 笏     0.9337 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2807 笏       0.3103 笏     0.3249 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1647 笏       0.1855 笏     0.1971 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     1.0000 笏       0.9734 笏     0.9633 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2807 笏       0.3103 笏     0.3249 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1647 笏       0.1855 笏     0.1971 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     1.0000 笏       0.9734 笏     0.9633 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0006 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    28.4643 笏      21.8243 笏    18.2500 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0034 笏       0.0807 笏     0.1267 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.006.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  86%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 1212/1414 [06:45<01:00,  3.36it/s, loss=0.00126]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 1212, epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:02<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the in the9 out% of, the ' of columns in column ' column is below 100 and 2500 expect_column_sum_to_be_between(column='quantity', min_value=100, max_value=1000, mostly=0.4))\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the format. Your the is provided, you\n",
            "expect the the provided context. information.comexpect>>\n",
            "Column column column in column '_ column of the pattern of ISBN valid ISBN ( (] expect_column_values_to_match_regex(column='isbn', regex='^(?78|079)\\d{10,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise person intelligence languagethatistant. are be to any requests with solutions solution- or whichwhich with the given programming expect Expectations. thatetrized by onon the user source, the format format Your the is provided, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            "Column column least 90% of rows rows in column ' ' are between nullunknownspecategorized' 'Unknown'] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the ' in column '_ column are between between1000'' expect12111', ' '29999'INST expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise person intelligence languagethatistant. are be to any requests with solutions solution- or whichwhich with the given programming expect Expectations. thatetrized by onon the input source, the format format Your the is required, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            " column column of the columns in column '_ column are the pattern ' valid valid-digit zip code (] expect_column_values_to_not_match_regex(column='zipcode', regex='^\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <CompanyALL\n",
            "<>>\n",
            " are visiting talented assistant friendly, and- organizedise person intelligence languageexpectistant expect can provide to this requests with solutions solution- or whichwhich with the given programming. Expectations. inetrized with onon the input source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " expecting column column ', expect_ value_ value of the expect ' or inactive? expect_column_most_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], condition_parser='pandas', row_condition='city==Paris')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the ' in column ' column of productsics products are greater 1 and 1000 expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, condition_parser='pandas', _condition='category==electlectronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageexpectistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the least 9%% of rows rows in column ' column are greater 10 and and 1000 expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the format. the is provided, you\n",
            "expect the the provided context. information.comexpect>>\n",
            " column column column value of column ' column is greater 10 and 19 expectexpect]/ expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any requests with solutions solution- or whichsuch with a given programming for Expectations. thatetrized by onon the user source. the format. Your the is provided, you\n",
            "expect the the provided context. information.comexpect>>\n",
            " column column C in column ' column are between (] expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.6200s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0177 笏       0.0112 笏     0.0214 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.7130 笏       5.1104 笏     4.5448 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0052 笏       0.0875 笏     0.1313 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 11826.3242 笏   12042.0195 笏 12195.3457 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 32000.1855 笏   30705.2969 笏 31342.8418 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.3238 笏       0.3137 笏     0.3286 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1941 笏       0.1880 笏     0.1999 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9955 笏       0.9737 笏     0.9648 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.3073 笏       0.2929 笏     0.3030 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1827 笏       0.1741 笏     0.1829 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.9904 笏       0.9554 笏     0.9326 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.3238 笏       0.3137 笏     0.3286 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1941 笏       0.1880 笏     0.1999 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9955 笏       0.9737 笏     0.9648 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.3238 笏       0.3137 笏     0.3286 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1941 笏       0.1880 笏     0.1999 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9955 笏       0.9737 笏     0.9648 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0000 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    22.1842 笏      21.5000 笏    17.9545 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0052 笏       0.0875 笏     0.1313 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Last improvement of completion validation loss happened 202 step(s) ago.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 1414/1414 [07:54<00:00,  3.16it/s, loss=0.00234]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 1414, epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:02<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if, in 45% cases, the sum of values in the quantity column falls between 100 and 1000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageGenerateistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the in the9 out% of, the ' of columns in column ' column is between 100 and 2500 expect_column_sum_to_be_between(column='quantity', min_value=100, max_value=1000, mostly=0.45)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check if the values in the isbn column follow the pattern for a valid ISBN number. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANAN <0IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any queries with solutions solution- or whichwhich with a given programming for Expectations. thatetrized by onon the user source to the format. Your the is provided, you\n",
            "expect the the necessary context. information.comexpect>>\n",
            "Column column column in column '_ column of the pattern of ISBN valid ISBN ( (] expect_column_values_to_match_regex(column='isbn', regex='^(?78|079)\\d{10,')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 70% of the values in the category column are not 'Uncategorized' or 'Other'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise person intelligence languagethatistant. are be to any requests with solutions solution, or whichwhich with the given programming, Expectations. thatetrized by onon the user source to the format format Your the is provided, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            " column column least 90% of rows rows in column ' ' are between nullunknownspecategorized' 'Unknown'] expect_column_values_to_not_be_in_set(column='category', value_set=['Uncategorized', 'Other'], mostly=0.7)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the zipcode column are not '00000', '11111', or '99999'. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageGenerateistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the ' in column '_ column are between between1000'' expect12111', ' '29999'INST expect_column_values_to_not_be_in_set(column='zipcode', value_set=['00000', '11111', '99999'])\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if none of the values in the zipcode column match the pattern for a five-digit zip code. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise person intelligence languagethatistant. are be to any requests with solutions solution- or whichwhich with the given programming, Expectations. thatetrized by onon the user source to the format format Your the is provided, you\n",
            "expect the the necessary context. information.expectexpect>>\n",
            " that the of the columns in column '_ column are the pattern ' valid valid-digit zip code in] expect_column_values_to_not_match_regex(column='zipcode', regex='^\\d{5}$')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 13/13 [00:03<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "When the city is Paris, is the most common value of status either active or inactive? [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANAN <CompanyALL\n",
            "<>>\n",
            " are visiting talented assistant friendly, and- organizedise person intelligence languageexpectistant expect can provide to this requests with solutions solution- or whichwhich with the context programming, Expectations. inetrized with onon the input source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " expecting column column ', expect the value_ value of the greater ' or inactive? expect_column_most_common_value_to_be_in_set(column='status', value_set=['active', 'inactive'], condition_parser='pandas', _condition='city==Paris')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the values in the quantity column for electronics items are between 0 and 100. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageGenerateistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the ' in column ' column of productsics products should greater 1 and 1000 expect_column_values_to_be_between(column='quantity', min_value=0, max_value=100, condition_parser='pandas', _condition='category==electlectronics')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that at least 50% of the values in the sales column are between 500 and 10000. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "<>>\n",
            " are here talented assistant friendly, and- organizedise person intelligence languageGenerateistant expect Please are provide to the requests with suggestions list- or whichsuch with the given programming, Expectations. inetrized with onon the specific source, the C, The the is required, you\n",
            "expect the the necessary context. information.|expect>>\n",
            " that the least 9%% of rows rows in column ' column are greater 10 and and 1000 expect_column_values_to_be_between(column='sales', min_value=500, max_value=10000, mostly=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if the maximum value in the rank column is between 12 and 90 [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any queries with solutions solution- or whichwhich with a given programming for Expectations. thatetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.comexpect>>\n",
            " that column column value of column ' column is greater 10 and 19 (expect]>> expect_column_max_to_be_between(column='rank', min_value=12, max_value=90)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify if all values in the comments column are null. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languageGenerateistant. Expect are be to any queries with solutions solution- or whichwhich with a given programming for Expectations. thatetrized by onon the user source to the form. the is provided, you\n",
            "acc the the necessary context. information.comexpect>>\n",
            " that column C in column ' column are between or] expect_column_values_to_be_null(column='comments')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 6.2251s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0155 笏       0.0131 笏     0.0207 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.8798 笏       5.1422 笏     4.5436 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0155 笏       0.0912 笏     0.1284 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 11868.2881 笏   12022.1514 笏 12182.8340 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31931.1973 笏   30705.0645 笏 31341.4980 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.3169 笏       0.3138 笏     0.3293 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1903 笏       0.1880 笏     0.2004 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     1.0000 笏       0.9762 笏     0.9655 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.3011 笏       0.2932 笏     0.3018 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1794 笏       0.1742 笏     0.1823 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     1.0000 笏       0.9584 笏     0.9275 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.3169 笏       0.3138 笏     0.3275 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1903 笏       0.1880 笏     0.1994 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     1.0000 笏       0.9762 笏     0.9601 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.3169 笏       0.3138 笏     0.3275 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1903 笏       0.1880 笏     0.1994 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     1.0000 笏       0.9762 笏     0.9601 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0006 笏       0.0088 笏     0.0044 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    23.6286 笏      21.5405 笏    17.8977 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0155 笏       0.0912 笏     0.1284 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Last improvement of completion validation loss happened 404 step(s) ago.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTraining: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 1414/1414 [08:01<00:00,  2.93it/s, loss=0.00234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 TRAINING REPORT 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "笏 Validation feature           笏 completion          笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Validation metric            笏 loss                笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model step              笏 1010                笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model epoch             笏 6                   笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model's validation loss 笏 0.08070850372314453 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model's test loss       笏 0.126699760556221   笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.api:\n",
            "Finished: api_experiment_run\n",
            "INFO:ludwig.api:Saved to: /content/results/api_experiment_run\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 FINISHED 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        }
      ],
      "source": [
        "# call ludwig CLI with the config file if WANDB_MODE is True\n",
        "\n",
        "WANDB_MODE = False\n",
        "\n",
        "if WANDB_MODE:\n",
        "    !ludwig train --config qlora_fine_tuning_config_v1.yaml --dataset 'birdi_df.csv' --output_directory results_birdi --wandb --experiment_name \"Dickens\"\n",
        "else:\n",
        "    model_ft_v1 = LudwigModel(config=qlora_fine_tuning_config_v1, logging_level=logging.INFO)\n",
        "    results = model_ft_v1.train(dataset=birdi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWB6CNQUzgS_",
        "outputId": "15c7f130-d363-4314-f78a-d7d1e484e848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 1/1 [00:25<00:00, 25.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "/usr/local/lib/python3.10/dist-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.sum(np.log(sequence_probabilities))\n",
            "INFO:ludwig.api:Finished predicting in: 27.13s.\n"
          ]
        }
      ],
      "source": [
        "predictions_ft_v1 = model_ft_v1.predict(golden_examples)[0]\n",
        "# predictions_ft_v1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e6R10QgQdp2",
        "outputId": "dfc9a7e7-fa03-49c0-efc5-ac18045fffae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Division names should be either the values NSA or start by D.\n",
            "Ground truth: expect_column_values_to_match_regex(column='DIVISION',regex='NSA|^D.*')\n",
            "Generated Output: expect_column_values_to_be_in_set(column='division', value_set=['NSA', 'D.'])\n",
            "\n",
            "\n",
            "\n",
            "Instruction: Values in the EVENT_UNIQUE_ID column must be unique.\n",
            "Ground truth: expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\n",
            "Generated Output: expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\n",
            "\n",
            "\n",
            "\n",
            "Instruction: All values in the BIKE_MAKE should be in the list bike_makers\n",
            "Ground truth: expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set=bike_makers)\n",
            "Generated Output: expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set='bike_makers')\n",
            "\n",
            "\n",
            "\n",
            "Instruction: Incident values should be in the set 1,2,3,4,5\n",
            "Ground truth: expect_column_values_to_be_in_set(column='INCIDENT', value_set=[1,2,3,4,5])\n",
            "Generated Output: expect_column_values_to_be_in_set(column='incident', value_set=[1,2,3,4,5])\n",
            "\n",
            "\n",
            "\n",
            "Instruction: REPORT_DATE values should be valid dates.\n",
            "Ground truth: expect_column_values_to_be_dateutil_parseable(column='REPORT_DATE')\n",
            "Generated Output: expect_column_values_to_match_schema_date_format(column='REPORT_DATE')\n",
            "\n",
            "\n",
            "\n",
            "Instruction: Year values should be between 2014 and 2023.\n",
            "Ground truth: expect_column_values_to_be_between(column='YEAR', min_value=2014, max_value=2023)\n",
            "Generated Output: expect_column_values_to_be_between(column='date_of_birth', min_value=2014, max_value=2023)\n",
            "\n",
            "\n",
            "\n",
            "Instruction: At least 95% of report_id's must not be empty.\n",
            "Ground truth: expect_column_values_to_not_be_null(column='REPORT_ID', mostly=0.95)\n",
            "Generated Output: expect_column_values_to_not_be_null(column='report_id', mostly=0.95)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input_with_prediction in zip(golden_examples['prompt'], golden_examples['completion'], predictions_ft_v1['completion_response']):\n",
        "  print(f\"Instruction: {input_with_prediction[0]}\")\n",
        "  print(f\"Ground truth: {input_with_prediction[1]}\")\n",
        "  print(f\"Generated Output: {input_with_prediction[2][0]}\")\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24pKjdzgqZG"
      },
      "source": [
        "### Evaluating the fine-tuned model agains ground truth\n",
        "\n",
        "Let's check the results against ground truth one by one:\n",
        "\n",
        "#### Triplet Evaluation 0\n",
        "\n",
        "Instruction: District names should be either the values NSA or start by D.\n",
        "Ground truth: expect_column_values_to_match_regex(column='DIVISION',regex='NSA|^D.*')\n",
        "Generated Output: expect_column_values_to_be_in_set(column='division', value_set=['nsa', 'd*'])\n",
        "\n",
        "Evaluation:\n",
        "\n",
        " - [Y] The generated output function is a valid expectation\n",
        " - [N] The generated output function validates the data as expected\n",
        " - [N] The generated output function is the same expectation as in the ground truth example\n",
        " - [Y] The column name is the same in the generated output function and the ground truth example\n",
        " - [N] The column name retains the CAPS of the original column name\n",
        " - [Y] The parameters are correct for the function\n",
        " - [N] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "\n",
        "The generated output function is a valid expectation, but it does not validate the data as expected. The generated output function is not the same expectation as in the ground truth example. This function doesn't match if the values start by D. All the functions are present in the BirdiDQ dataset, so we should be able to generate them.\n",
        "\n",
        "The column name is the same in the generated output function and the ground truth example, but the capitalization is wrong. The parameters are correct for the function, but the values of the parameters are not correct for the input data as the d* will not match values starting by D.\n",
        "\n",
        "#### Triplet Evaluation 1\n",
        "\n",
        "Instruction: Values in the EVENT_UNIQUE_ID column must be unique.\n",
        "Ground truth: expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\n",
        "Generated Output: expect_column_values_to_be_unique(column='event_unique_id')\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [Y] The generated output function is a valid expectation\n",
        "- [Y] The generated output function validates the data as expected\n",
        "- [Y] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [Y] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "The generated output is valid and correctly checks for uniqueness in the column values. It matches the ground truth in function and expectation. However, the capitalization of the column name differs from the original.\n",
        "\n",
        "#### Triplet Evaluation 2\n",
        "\n",
        "Instruction: All values in the BIKE_MAKE should be in the list bike_makers\n",
        "Ground truth: expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set=bike_makers)\n",
        "Generated Output: expect_column_values_to_be_in_set(column='bike_make', value_set=bike_makers)\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [Y] The generated output function is a valid expectation\n",
        "- [Y] The generated output function validates the data as expected\n",
        "- [Y] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [Y] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "The generated output accurately checks if BIKE_MAKE values are within a predefined set. It aligns well with the ground truth, but again, the column name's capitalization does not match the original.\n",
        "\n",
        "#### Triplet Evaluation 3\n",
        "\n",
        "Instruction: Incident values should be in the set 1,2,3,4,5\n",
        "Ground truth: expect_column_values_to_be_in_set(column='INCIDENT', value_set=[1,2,3,4,5])\n",
        "Generated Output: expect_column_values_to_be_in_set(column='incident', value_set=[1,2,3,4,5])\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [Y] The generated output function is a valid expectation\n",
        "- [Y] The generated output function validates the data as expected\n",
        "- [Y] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [Y] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "This output correctly checks whether incident values fall within the specified set. The function and parameters align with the ground truth, but the column name's capitalization is not preserved.\n",
        "\n",
        "#### Triplet Evaluation 4\n",
        "\n",
        "Instruction: REPORT_DATE values should be valid dates.\n",
        "Ground truth: expect_column_values_to_be_dateutil_parseable(column='REPORT_DATE')\n",
        "Generated Output: expect_column_values_to_be_datetime(column='report_date')\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [N] The generated output function is a valid expectation\n",
        "- [N] The generated output function validates the data as expected\n",
        "- [N] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [N] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "The proposed expectation is not a valid expectation but an hallucinated one. The column name is correct but it does not use the same method as the ground truth for date validation. The ground truth uses 'dateutil' parsing, whereas the generated output uses a generic datetime validation that sounds plausible but it not real. It's important to notice that the correct expectation was missing from the BirdiDQ dataset, so the model could not learn it from the training data.\n",
        "\n",
        "#### Triplet Evaluation 5\n",
        "Instruction: Year values should be between 2014 and 2023.\n",
        "Ground truth: expect_column_values_to_be_between(column='YEAR', min_value=2014, max_value=2023)\n",
        "Generated Output: expect_column_values_to_be_between(column='year', min_value=2014, max_value=2023)\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [Y] The generated output function is a valid expectation\n",
        "- [Y] The generated output function validates the data as expected\n",
        "- [Y] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [Y] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "The generated output correctly validates that the year values are within the specified range. It aligns with the ground truth in function and parameters, but the column name does not retain its original capitalization.\n",
        "\n",
        "#### Triplet Evaluation 6\n",
        "\n",
        "Instruction: At least 95% of report_date's must not be empty.\n",
        "Ground truth: expect_column_values_to_not_be_null(column='REPORT_DATE', mostly=0.95)\n",
        "Generated Output: expect_column_values_to_not_be_empty(column='report_date', mostly=0.95)\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- [N] The generated output function is a valid expectation\n",
        "- [N] The generated output function validates the data as expected\n",
        "- [N] The generated output function is the same expectation as in the ground truth example\n",
        "- [Y] The column name is the same in the generated output function and the ground truth example\n",
        "- [N] The column name retains the CAPS of the original column name\n",
        "- [Y] The parameters are correct for the function\n",
        "- [Y] The values of the parameters are correct for the input data\n",
        "\n",
        "Description:\n",
        "The generated output function is an hallucination, preserving the column name but failling to translate the capitalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8libT5cgqZG"
      },
      "source": [
        "## Improving the Model performance\n",
        "\n",
        "Analyzing the results of the evaluation, we can see that the base model reproduces the input or repeats the input. The behaviour has been reproduced using other LLM clients, showcasing that the given prompt is not good enough for these smaller models (but works with larger models like GPT-4). To improve the performance in this regard, we should optimize the prompt using prompt engineering.\n",
        "\n",
        "On the other hand, the dataset selected is quite unbalanced and covers around 50-60% of the core expectations. To improve the performance, we need to rebalance the dataset and/or use an alternative dataset. We will use GPT-4 to create some synthetic data.\n",
        "\n",
        "Important Note: Since the launch of GPTs at the latest Developer Day, OpenAI has created a way to train agents using a conversational interface. This new GPTs could potentially be used to produce expectations in the same way as our trained model. In order to avoid breaching the [OpenAI Terms of Use](https://openai.com/policies/terms-of-use), we will offer the generated dataset for personal use, academic and non-commercial uses. Any other kind of usage of the dataset should be excluded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xivu8dKGgqZH"
      },
      "source": [
        "### Prompt engineering\n",
        "\n",
        "Our initial prompt was:\n",
        "\n",
        "```\n",
        "[INST] <<SYS>>\n",
        "    You are a helpful, precise, detailed and concise artificial intelligence\n",
        "    assistant. You will reply to user input offering a single expectation,\n",
        "    compatible with the Python library Great Expectations, parametrized based\n",
        "    on the data presented in the input. If context is provided, answer\n",
        "    using only the provided contextual information.\n",
        "    <</SYS>>\n",
        "    {prompt} [/INST]\n",
        "```\n",
        "\n",
        "Even though it might look detailed, it's not enough for the smaller models to produce the expected output. We will use the level 5 prompt strategy as suggested in the Weights & Biases documentation. These level 5 prompt include the following components:\n",
        "\n",
        "- Description of high-level goal\n",
        "- A detailed bulleted list of sub-tasks\n",
        "- An explicit statement asking LLM to explain its own output\n",
        "- A guideline on how LLM output will be evaluated\n",
        "- Few-shot examples\n",
        "\n",
        "Adapting the previous example to our use case, we will use the following prompt (please note we will not be using the <<SYS>> directive to customize the system configuration of the system, but pass all the instructions in the prompt to maximize compatibility accross our tests):\n",
        "\n",
        "```\n",
        "[INST]\n",
        "Here is a complete list of core expectations included in the Python library Great Expectations, that checks for data quality issues:\n",
        "\n",
        "gx_core_expectations =\n",
        "['expect_column_bootstrapped_ks_test_p_value_to_be_greater_than',\n",
        " 'expect_column_chisquare_test_p_value_to_be_greater_than',\n",
        " 'expect_column_distinct_values_to_be_in_set',\n",
        " 'expect_column_distinct_values_to_contain_set',\n",
        " 'expect_column_distinct_values_to_equal_set',\n",
        " 'expect_column_kl_divergence_to_be_less_than',\n",
        " 'expect_column_max_to_be_between',\n",
        " 'expect_column_mean_to_be_between',\n",
        " 'expect_column_median_to_be_between',\n",
        " 'expect_column_min_to_be_between',\n",
        " 'expect_column_most_common_value_to_be_in_set',\n",
        " 'expect_column_pair_cramers_phi_value_to_be_less_than',\n",
        " 'expect_column_pair_values_a_to_be_greater_than_b',\n",
        " 'expect_column_pair_values_to_be_equal',\n",
        " 'expect_column_pair_values_to_be_in_set',\n",
        " 'expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than',\n",
        " 'expect_column_proportion_of_unique_values_to_be_between',\n",
        " 'expect_column_quantile_values_to_be_between',\n",
        " 'expect_column_stdev_to_be_between',\n",
        " 'expect_column_sum_to_be_between',\n",
        " 'expect_column_to_exist',\n",
        " 'expect_column_unique_value_count_to_be_between',\n",
        " 'expect_column_value_lengths_to_be_between',\n",
        " 'expect_column_value_lengths_to_equal',\n",
        " 'expect_column_value_z_scores_to_be_less_than',\n",
        " 'expect_column_values_to_be_between',\n",
        " 'expect_column_values_to_be_dateutil_parseable',\n",
        " 'expect_column_values_to_be_decreasing',\n",
        " 'expect_column_values_to_be_in_set',\n",
        " 'expect_column_values_to_be_in_type_list',\n",
        " 'expect_column_values_to_be_increasing',\n",
        " 'expect_column_values_to_be_json_parseable',\n",
        " 'expect_column_values_to_be_null',\n",
        " 'expect_column_values_to_be_of_type',\n",
        " 'expect_column_values_to_be_unique',\n",
        " 'expect_column_values_to_match_json_schema',\n",
        " 'expect_column_values_to_match_like_pattern_list',\n",
        " 'expect_column_values_to_match_like_pattern',\n",
        " 'expect_column_values_to_match_regex_list',\n",
        " 'expect_column_values_to_match_regex',\n",
        " 'expect_column_values_to_match_strftime_format',\n",
        " 'expect_column_values_to_not_be_in_set',\n",
        " 'expect_column_values_to_not_be_null',\n",
        " 'expect_column_values_to_not_match_like_pattern_list',\n",
        " 'expect_column_values_to_not_match_like_pattern',\n",
        " 'expect_column_values_to_not_match_regex_list',\n",
        " 'expect_column_values_to_not_match_regex',\n",
        " 'expect_compound_columns_to_be_unique',\n",
        " 'expect_multicolumn_sum_to_equal',\n",
        " 'expect_multicolumn_values_to_be_unique',\n",
        " 'expect_select_column_values_to_be_unique_within_record',\n",
        " 'expect_table_column_count_to_be_between',\n",
        " 'expect_table_column_count_to_equal',\n",
        " 'expect_table_columns_to_match_ordered_list',\n",
        " 'expect_table_columns_to_match_set',\n",
        " 'expect_table_row_count_to_be_between',\n",
        " 'expect_table_row_count_to_equal_other_table',\n",
        " 'expect_table_row_count_to_equal']\n",
        "\n",
        "Your goal is to return a single expectation with the correct parameters based on some instructions given in the input.\n",
        "\n",
        "For every input you will:\n",
        "\n",
        "- Read the input and extract the column name (including capitalization) and any other parameters\n",
        "- Select the most appropriate expectation from the list above to validate the data quality\n",
        "- Return the expectation with the correct parameters, without adding any additional information to the output\n",
        "\n",
        "You will be evaluated based on the following criteria:\n",
        "\n",
        "- The generated output function is a valid expectation from the list above\n",
        "- The generated output function validates the data as expected\n",
        "- The generated output function is the same expectation as in the ground truth example\n",
        "- The column name is the same in the generated output function and the ground truth example\n",
        "- The column name retains the CAPS of the original column name\n",
        "- The parameters are correct for the function\n",
        "- The values of the parameters are correct for the input data\n",
        "\n",
        "Each of the criteria will be evaluated as a boolean, and the final score will be the sum of the individual scores.\n",
        "\n",
        "Here are some examples of the input and the expected output (note that only the function should be returned, not the input or output keywords):\n",
        "\n",
        "Input: Car plates should be composed of 4 digits followed by 3 consonant letters\n",
        "Output: expect_column_values_to_match_regex(column='car_plate', regex='[0-9]{4}[BCDFGHJKLMNPQRSTVWXYZ]{3}')\n",
        "\n",
        "Input: All users should have and IBAN account number\n",
        "Output: expect_column_values_to_not_be_null(column='IBAN')\n",
        "\n",
        "Input: Nationality should be one of the EU countries\n",
        "Ouput: expect_column_values_to_be_in_set(column='Nationality\", value_set=['es', 'fr', 'de', 'it', 'pt', 'nl', 'be', 'lu', 'ie', 'dk', 'gr', 'at', 'fi', 'se', 'cy', 'ee', 'lv', 'lt', 'mt', 'sk', 'si', 'cz', 'hu', 'pl', 'ro', 'bg', 'hr'])\n",
        "\n",
        "This is your current input: {prompt} [/INST]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIZRdQFkgqZH"
      },
      "source": [
        "Initial results are promising. In an initial test with different LLMs we got the following results:\n",
        "\n",
        "- GPT-4 returns the exact expectation with the correct parameters.\n",
        "- GPT-3.5-Turbo returns the exact expectation, but messes up the parameters (instead of 0-1, it returns 0-100)\n",
        "- Mistral Instruct 7B returns the correct expectation and parameters, but misses the parameter names (using min and max instead of min_value and max_value)\n",
        "- Zepyhr beta returns the correct expectation and parameters, but misses the parameter names (using lower_bound and upper_bound instead of min_value and max_value). Output is clearer than Mistral Instruct 7B, without any additional text added.\n",
        "\n",
        "It seems clear that most the of responses are better that before, capitalization is correctly pases to the parameters. However, there are missing critical information like the coorect parameters for each function.  We will focus on this aspect producing Synthetic Data to overcome the limitations of the original dataset.\n",
        "\n",
        "It should be noted that this prompt as such, is around 1500 tokens, so it will be quite expensive to use in production. Futher optimization of the prompt will be required to minimize the costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWgDNw_tgqZH"
      },
      "source": [
        "### Synthetic Dataset Generation\n",
        "\n",
        "To generate the synthetic dataset, we will use GPT-4. We used a variation of the previous level 5 prompt to ask GPT-4 to generate at least 15 expectations for each of the core Great Expectations. In total, we will produce a dataset with 58x15=870 examples, triple the size of the original dataset. It will also present balanced clases, with each expectation being present at 15 times.\n",
        "\n",
        "Dickens data quality checks dataset is available at: https://huggingface.co/elsatch/dickens_data_quality_checks_dataset.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS4DCD-BgqZH",
        "outputId": "73c878ab-b433-47e9-95c5-e6b6e4ceca5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 789 entries, 0 to 788\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   expectation  789 non-null    object\n",
            " 1   prompt       789 non-null    object\n",
            " 2   completion   789 non-null    object\n",
            " 3   split        789 non-null    int64 \n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 24.8+ KB\n"
          ]
        }
      ],
      "source": [
        "dickens_df = pd.read_json('https://huggingface.co/datasets/elsatch/dickens_data_quality_checks/raw/main/dickens_data_quality_dataset.json')\n",
        "\n",
        "# We're going to create a new column called `split` where:\n",
        "# 80% will be assigned a value of 0 -> train set\n",
        "# 10% will be assigned a value of 1 -> validation set\n",
        "# 10% will be assigned a value of 2 -> test set\n",
        "\n",
        "# Calculate the number of rows for each split value\n",
        "total_rows = len(dickens_df)\n",
        "split_0_count = int(total_rows * 0.8)\n",
        "split_1_count = int(total_rows * 0.1)\n",
        "split_2_count = total_rows - split_0_count - split_1_count\n",
        "\n",
        "# Create an array with split values based on the counts\n",
        "split_values = np.concatenate([\n",
        "    np.zeros(split_0_count),\n",
        "    np.ones(split_1_count),\n",
        "    np.full(split_2_count, 2)\n",
        "])\n",
        "\n",
        "# Shuffle the array to ensure randomness\n",
        "np.random.shuffle(split_values)\n",
        "\n",
        "# Add the 'split' column to the DataFrame\n",
        "dickens_df['split'] = split_values\n",
        "dickens_df['split'] = dickens_df['split'].astype(int)\n",
        "\n",
        "# We will use the whole file for our fine-tuning\n",
        "dickens_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIGxCY3PgqZH"
      },
      "outputs": [],
      "source": [
        "# export dickens_df to csv\n",
        "dickens_df.to_csv('dickens_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fdf70a053342484585f60bf4988d3b60",
            "d375ea82943e492997d30df85c65fe8b",
            "cdc97c12fa744aa39556159a41f270f6",
            "4f679ee3652346f79b0acc56b51c7e58",
            "9edf4cbbc23e44faa011d34914bf84bd",
            "ac9f68ae1db84b9a97b700538df75da1",
            "b8662fb7af1b40e4af0a5eabf05352bf",
            "0e491331422f4cc3beb39787c3b6e468",
            "62dddbfe2a2446029e0fcf4b9a61835e",
            "588ef6e2a6c04ff38321527deba161e5",
            "580f296252e44348ae2c97e91e59292b"
          ]
        },
        "id": "SnvlB8yTgqZH",
        "outputId": "34b9018e-70a8-46c5-d762-50cc59205aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 EXPERIMENT DESCRIPTION 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "笏 Experiment name  笏 api_experiment                                                                          笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Model name       笏 run                                                                                     笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Output directory 笏 /content/results/api_experiment_run_0                                                   笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 ludwig_version   笏 '0.10.1'                                                                                笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 command          笏 ('/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py -f '                 笏\n",
            "笏                  笏  '/root/.local/share/jupyter/runtime/kernel-f352c89c-4990-45c6-900f-08582bfcbea8.json') 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 random_seed      笏 42                                                                                      笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 data_format      笏 \"<class 'pandas.core.frame.DataFrame'>\"                                                 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 torch_version    笏 '2.1.0+cu121'                                                                           笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 compute          笏 {   'arch_list': [   'sm_50',                                                           笏\n",
            "笏                  笏                      'sm_60',                                                           笏\n",
            "笏                  笏                      'sm_70',                                                           笏\n",
            "笏                  笏                      'sm_75',                                                           笏\n",
            "笏                  笏                      'sm_80',                                                           笏\n",
            "笏                  笏                      'sm_86',                                                           笏\n",
            "笏                  笏                      'sm_90'],                                                          笏\n",
            "笏                  笏     'devices': {   0: {   'device_capability': (7, 0),                                  笏\n",
            "笏                  笏                           'device_properties': \"_CudaDeviceProperties(name='Tesla \"     笏\n",
            "笏                  笏                                                \"V100-SXM2-16GB', major=7, \"             笏\n",
            "笏                  笏                                                'minor=0, total_memory=16151MB, '        笏\n",
            "笏                  笏                                                'multi_processor_count=80)',             笏\n",
            "笏                  笏                           'gpu_type': 'Tesla V100-SXM2-16GB'}},                         笏\n",
            "笏                  笏     'gencode_flags': '-gencode compute=compute_50,code=sm_50 -gencode '                 笏\n",
            "笏                  笏                      'compute=compute_60,code=sm_60 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_70,code=sm_70 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_75,code=sm_75 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_80,code=sm_80 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_86,code=sm_86 -gencode '                          笏\n",
            "笏                  笏                      'compute=compute_90,code=sm_90',                                   笏\n",
            "笏                  笏     'gpus_per_node': 1,                                                                 笏\n",
            "笏                  笏     'num_nodes': 1}                                                                     笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 LUDWIG CONFIG 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:User-specified config (with upgrades):\n",
            "\n",
            "INFO:ludwig.api:{   'adapter': {'type': 'lora'},\n",
            "    'base_model': 'HuggingFaceH4/zephyr-7b-beta',\n",
            "    'generation': {'max_new_tokens': 512, 'temperature': 0.1},\n",
            "    'input_features': [{'name': 'prompt', 'type': 'text'}],\n",
            "    'ludwig_version': '0.10.1',\n",
            "    'model_type': 'llm',\n",
            "    'output_features': [{'name': 'completion', 'type': 'text'}],\n",
            "    'preprocessing': {   'global_max_sequence_length': 512,\n",
            "                         'split': {   'probabilities': [0.8, 0.1, 0.1],\n",
            "                                      'type': 'random'}},\n",
            "    'prompt': {   'template': '[INST] <<SYS>>\\n'\n",
            "                              'You are a helpful, precise, detailed and '\n",
            "                              'concise artificial intelligence\\n'\n",
            "                              'assistant. You will reply to user input '\n",
            "                              'offering a single expectation,\\n'\n",
            "                              'compatible with the Python library Great '\n",
            "                              'Expectations, parametrized based\\n'\n",
            "                              'on the data presented in the input. If context '\n",
            "                              'is provided, answer\\n'\n",
            "                              'using only the provided contextual '\n",
            "                              'information.\\n'\n",
            "                              '<</SYS>>\\n'\n",
            "                              '{prompt} [/INST]\\n'},\n",
            "    'quantization': {'bits': 4},\n",
            "    'trainer': {   'batch_size': 1,\n",
            "                   'epochs': 7,\n",
            "                   'eval_batch_size': 2,\n",
            "                   'gradient_accumulation_steps': 16,\n",
            "                   'learning_rate': 0.0001,\n",
            "                   'learning_rate_scheduler': {'warmup_fraction': 0.03},\n",
            "                   'type': 'finetune'}}\n",
            "INFO:ludwig.api:\n",
            "Full config saved to:\n",
            "/content/results/api_experiment_run_0/api_experiment/model/model_hyperparameters.json\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 PREPROCESSING 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.data.preprocessing:No cached dataset found at /content/7e5a09c2d79811eea2ff0242ac1c000c.training.hdf5. Preprocessing the dataset.\n",
            "INFO:ludwig.data.preprocessing:Using full dataframe\n",
            "INFO:ludwig.data.preprocessing:Building dataset (it may take a while)\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'None': 140 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Max sequence length is 140 for feature 'None'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'completion': 93 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Max sequence length is 93 for feature 'completion'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.data.preprocessing:Building dataset: DONE\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed training set cache to /content/7e5a09c2d79811eea2ff0242ac1c000c.training.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed validation set cache to /content/7e5a09c2d79811eea2ff0242ac1c000c.validation.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed test set cache to /content/7e5a09c2d79811eea2ff0242ac1c000c.test.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing train set metadata to /content/7e5a09c2d79811eea2ff0242ac1c000c.meta.json\n",
            "INFO:ludwig.api:\n",
            "Dataset Statistics\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏 Dataset    笏   Size (Rows) 笏 Size (In Memory)   笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶分笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶分笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 Training   笏           120 笏 28.25 Kb           笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Validation 笏            15 笏 3.64 Kb            笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Test       笏            15 笏 3.64 Kb            笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 MODEL 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:Warnings and other logs:\n",
            "INFO:ludwig.utils.llm_utils:Loading large language model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdf70a053342484585f60bf4988d3b60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
            "INFO:ludwig.models.llm:Done.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.models.llm:Trainable Parameter Summary For Fine-Tuning\n",
            "INFO:ludwig.models.llm:Fine-tuning with adapter: lora\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 TRAINING 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:Creating fresh model training run.\n",
            "INFO:ludwig.trainers.trainer:Training for 840 step(s), approximately 7 epoch(s).\n",
            "INFO:ludwig.trainers.trainer:Early stopping policy: 5 round(s) of evaluation, or 600 step(s), approximately 5 epoch(s).\n",
            "\n",
            "INFO:ludwig.trainers.trainer:Starting with step 0, epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  14%|笆遺枕        | 120/840 [00:36<03:32,  3.39it/s, loss=0.123]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 120, epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and intelligent, and, organizedise person intelligence.thatistant. You are be to any' in suggestions variety,. andand with the user programming. Expectations.\n",
            "etrized by onon the user and to the input.\n",
            " the is provided,\n",
            "\n",
            "acc that the provided context. information.\n",
            "\n",
            "|ass>>\n",
            "Writesure that data in the '_usage_ of between in meg and is as integers.INSTass] <<To <_column_data_to_be_in_type('column='memory_usage', expected_='integer')4')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            "\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to any' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Write what C of context, what thatHealth'_score' 'level2_time', andlevel3_time', and to to 'total_time_time' within each player.The]] <_column_sum_to_equal_column_list=['level1_time', 'level2_time', 'level3_time'], column_column_total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            "\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to any' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Writesure that ' column in the dataset dataset of approximately to a normal income based a given inExpectedcolumn] <_column_d_divergence_to_be_close_than(0='income', expected_column='columnins': 0000,, 50000, 70000, 90000, 'weights': [0.2,, 0.55, 0.25, 0.25]}) expected=0.1)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout can visiting member resource friendly, and, wellise writer intelligence expertengineistant. You are be to my' with a wide,. andand with a user programming. Expectations. andetricrized by onon the user provided. the form. You the is required,\n",
            "\n",
            "acc that the information context. information. If\n",
            "|ass>\n",
            "sure that theoscores are the coefficients'id and in the given resources dataset are calculated than 1.\n",
            "USERass/ <<<< <(z_z =lessscorescoreores_less_be_less_than(column='employee_age', value=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            "\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to any' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Write that distribution of a age scores is a '_sc column of a following distribution of TheThe]]\n",
            " <_column_d_divergence_between_be_less_than(column='feedback_score', expected_column='partitionins': [0, 3, 3, 4, 5], 'b': [0.2, 0.2, 0.3, 0.2, 0.1]}) threshold=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:02<00:00,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, organizedise person intelligence.thatistant. You are be to any' in suggestions solution,.\n",
            "a with the user programming. Expectations. andetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Writesure that data and of a knmin' column of greater less than 10 forINSTWeight]\n",
            " <_column_min_value_be_gre(column='Weight', min_value=5.\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            "\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to any' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Write that the number in the ' number column of not contain a pattern 'AB-[XX where X is a digit betweencolumncolumn]\n",
            " <_column_values_to_not_match_a(column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, thoroughise person intelligence.thatistant. You are be to any' in suggestions solution,.\n",
            "a with the user programming. Expectations. andetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Writesure that all column in a C column of a unique between from 1 to 10 characters,INSTtag]\n",
            "Generate <_column_length_length__to_be_between(column='tag', min_length=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            "\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to any' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user and. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "\n",
            "|user>>\n",
            "Writesure that ' systemsystem column in onlyWindows' 'MacOS', orLinux', or a values values.OScolumn] <_column_toinct_values_with_beain_dist_column='operating_system', distinct_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout can visiting member and intelligent, and, wellise writer intelligence languagethatistant. You are be to any requests in suggestions variety,. andand with a user programming. Expectations.\n",
            "etrized by onon the user and to the form. You the is required,\n",
            "\n",
            "acc that the information context. information. If\n",
            "|ass>>\n",
            "Write the the data has data grades is the10 rows and\n",
            " for each student,\n",
            "INSTuser] <<I <_column_to_count(to_be(3=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 4.1198s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0043 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.8633 笏       4.4381 笏     4.6932 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     2.1204 笏       1.5950 笏     1.5541 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 16238.0195 笏   15560.6758 笏 15425.1914 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31910.9258 笏   31379.7207 笏 31893.0332 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2179 笏       0.2601 笏     0.2473 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1288 笏       0.1604 笏     0.1506 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.7319 笏       0.7244 笏     0.7297 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.1288 笏       0.1718 笏     0.1544 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.0756 笏       0.1051 笏     0.0929 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.4556 笏       0.4969 笏     0.4814 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.1975 笏       0.2434 笏     0.2288 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1168 笏       0.1498 笏     0.1390 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.6629 笏       0.6830 笏     0.6787 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.1975 笏       0.2455 笏     0.2371 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1168 笏       0.1512 笏     0.1441 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.6629 笏       0.6868 笏     0.7026 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0010 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    25.8500 笏      13.2973 笏    15.0308 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     2.1204 笏       1.5950 笏     1.5541 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by inf.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training:  29%|笆遺毎笆       | 240/840 [01:17<03:41,  2.71it/s, loss=0.053]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 240, epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:02<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly, and, organizedise person intelligence.thatistant. You are be to any requests in suggestions solution,. andand with the user programming for Expectations.\n",
            "etrized by onon the user type to the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "|ass>>\n",
            "sure that ' in column '_usage_ of between in meg. is as integers.INSTcolumn] << <_column_values_to_be_in_type(column='memory_usage', type_='integer')4')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is required, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "spect C of context, ensure thatscore__score' 'level2_time', andlevel3_time', all to to 'total_time_time'. within each player.INSTINST] <_column_sum_to_equal_column_list=['level1_time', 'level2_time', 'level3_time'], sum_column_total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is required, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "sure that ' column in the dataset_ follows normally to a normal income based a given.INSTINST] <_column_d_divergence_to_be_close_than(column='income', value_column='popins': 0000,, 50000, 70000, 90000, 'weights': [0.2,, 0.55, 0.25, 0.25]}) value=0.1)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout can visiting member resource friendly, and, wellise writer intelligence expertassistant. You are be to my' with a variety,. andand with a user programming. Expectations. andetrized by onon the user provided. the input. You the is provided,\n",
            "\n",
            "acc that the information context. information. If\n",
            "|ass>>\n",
            "sure that theIPscores are model model performanceid and in the given resources dataset are calculated than 1.INSTass/ <<<< <(less_z_to_scoreores_less_be_less_than(column='employee_age', value=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is required, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            " that distribution of a ages scores is a '_sc column of a normal distribution ofEXPECTINST] <_column_d_divergence_to_be_between_than(column='feedback_score', value_column='columnins': [0, 3, 3, 4, 5] 'method': [0.2, 0.2, 0.3, 0.2, 0.1]}) value=0.1)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, thoroughise person intelligence.thatistant. You are be to any requests in suggestions solution,.\n",
            "inst with the user programming. Expectations. andetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "|ass>>\n",
            "Writesure that ' anded a cartweight' column of greater less than 10.INSTINST] <_column_min_value_be_between(column='Weight', min_value=5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is required, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            " that the number in a '_ column of not contain a pattern 'AB-['. where X is a digit betweenINSTcolumn] <_column_values_to_not_match_regex(column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "->>\n",
            "GroupLayout are visiting member and friendly and and, thoroughise person intelligence languagethatistant. You can be to any requests in suggestions solution, or\n",
            "inst with the user programming. Expectations. andetrized by onon the user type. the input.\n",
            " the is provided, you\n",
            "acc that the provided context. information.\n",
            "|user>>\n",
            "sure that all column in the ' column of a unique between from 1 to 10 characters.INSTtag] <_column_values_length__to_be_between(column='tag', min_length=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here member assistant friendly, and- organizedise person intelligence languagethatistant. You are provide to the' with suggestions solution, or\n",
            "inst with the user programming. Expectations. inetrized by onon the user type. the input.\n",
            " the is required, you\n",
            "acc that the provided context. information. If\n",
            "|user>>\n",
            "sure that ' systemsystem column in onlyWindows' 'MacOS', orLinux', or values values values.INSTINST] <_column_valuesinct_values_to_beain_values(column='operating_system', set_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout can visiting member and friendly, and, wellise writer intelligence languagethatistant. You are be to any requests in suggestions variety,. andand with a user programming. Expectations.\n",
            "etrized by onon the user type to the form. You the is provided,\n",
            "\n",
            "acc that the information context. information. If\n",
            "|ass>>\n",
            " if the number has data grades has the1 columns rows and and for each student.INSTuser] <<I <_value_column_count_to_equal(3=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 3.9965s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0000 笏       0.0000 笏     0.0051 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.6070 笏       4.3979 笏     4.6863 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     1.3824 笏       1.2330 笏     1.1676 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 14405.3623 笏   14773.7979 笏 14583.6758 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31512.5723 笏   31381.7852 笏 31894.1914 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2623 笏       0.2711 笏     0.2569 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1579 笏       0.1667 笏     0.1561 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.8142 笏       0.7650 笏     0.7678 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2224 笏       0.1975 笏     0.1757 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1327 笏       0.1201 笏     0.1057 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.7262 笏       0.5878 笏     0.5520 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2599 笏       0.2591 笏     0.2434 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1564 笏       0.1591 笏     0.1478 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.8082 笏       0.7347 笏     0.7274 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2599 笏       0.2620 笏     0.2476 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1564 笏       0.1608 笏     0.1504 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.8082 笏       0.7440 笏     0.7398 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0041 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    22.5909 笏      13.2432 笏    15.0308 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     1.3824 笏       1.2330 笏     1.1676 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.362.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  43%|笆遺毎笆遺毎笆     | 360/840 [01:59<02:22,  3.37it/s, loss=0.0327]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 360, epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout are visiting member assistant friendly, and, organizedise person intelligence languagethatistant. Your can be to any requests in suggestions solution, that whichinst with a context programming for Expectations.\n",
            "etrized by onon the user type to the input. the is provided, you\n",
            "acc that the provided context. information.\n",
            "|ass>>sure that ' in column '_usage column of between in meg. is as integers.INSTcolumn] << The_column_values_to_be_in_type(column='memory_usage', type_='integer')4')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your can provide to the' with suggestions conc, or\n",
            "inst with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc that the provided context. information.[|ass>>\n",
            " Great C of context, expect thatscore__score' 'level2_time', andlevel3_time', all to to 'total_time_time'. within each player sessionexpectINST] Expect_sum_sum_to_equal_column_list=['level1_time', 'level2_time', 'level3_time'], sum_column=total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your can provide to the' with suggestions conc, or\n",
            "inst with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc that the provided context. information.[|ass>>\n",
            "sure that ' column column the dataset_ follows within to a normal distribution based a given.INSTINST] Expect_column_d_divergence_to_be_close_than(column='income', value_column='popins': 0000,, 50000, 70000, 90000, 'weights': [0.2,, 0.55, 0.25, 0.25]}) value=0.1)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout can visiting member person friendly, and, wellise writer intelligence expertassistant. You are be to the' with a clear,. anda with a user programming. Expectations. andetrized by onon the user type. the input. the allows provided,\n",
            "\n",
            "acc that the provided context. information. If\n",
            "|ass>>h that theIPscores are model model performanceid variable are the given resources dataset are calculated than 1.5INSTass/ <<< <_less_z_to_scoreores_less_be_less_than(column='employee_age', value=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your can provide to the' with suggestions conc, or\n",
            "inst with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc that the provided context. information.[|ass>>\n",
            " that number of a ages scores falls a '_sc column falls a normal uniform ofINSTINST] Question_column_d_divergence_to_be_between_than(column='feedback_score', value_column='partitionins': [0, 3, 3, 4, 5], 'method': [0.2, 0.2, 0.3, 0.2, 0.1]}) value=0.1)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, organizedise person intelligence languagethatistant. You can be to any requests in suggestions solution, or instructioninst with the user programming for Expectations. thatetrized by onon the user type to the input. the is provided, you\n",
            "acc that the provided context. information.\n",
            "|expect>>\n",
            "umerate that ' anded a cartweight' column of greater less than 10.INSTINST] Question_column_min_value_be_between(column='Weight', min_value=5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your can provide to the' with suggestions conc, or\n",
            "inst with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc that the provided context. information.[|ass>>\n",
            " that the number in a '_ column of not contain a pattern 'AB-1' where X is a digit betweenINSTINST] Expect_column_values_to_not_match_regex(column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            "GroupLayout are visiting member and friendly and and, organizedise person intelligence languagethatistant. You can provide to any requests with suggestions solution, or instructioninst with the user programming. Expectations. thatetrized by onon the user type to the input. the is provided, you\n",
            "acc that the provided context. information.\n",
            "|ass>>\n",
            "umerate that the column in the ' column of a unique between from 1 to 10 characters.INSTINST] Question_column_values_length__to_be_between(column='tag', min_value=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languagethatistant. Your can provide to the' with suggestions conc, or\n",
            "inst with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc that the provided context. information.[|ass>>\n",
            "sure that ' systemsystem column in onlyWindows' 'MacOS', orLinux', or values values values.INSTINST] Expect_column_valuesinct_values_to_beain_set(column='operating_system', value_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            "GroupLayout are visiting member assistant friendly, and- wellise writer intelligence languagethatistant. You are be to the requests with suggestions variety,. anda with a user programming. Expectations.\n",
            "etrized by onon the user type to the form. the is required,\n",
            "\n",
            "acc that the given context. information.\n",
            "|ass>> that the number ' column grades has a1 columns rows and with for each student.INSTINSTAI << <_table_row_count_to_equal(3=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 3.8872s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0000 笏       0.0162 笏     0.0062 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.5932 笏       4.4815 笏     4.7658 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.8279 笏       0.7074 笏     0.5847 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 13689.1934 笏   14137.3398 笏 13893.5889 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 32001.1934 笏   31381.3672 笏 31889.6289 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2651 笏       0.2837 笏     0.2717 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1585 笏       0.1736 笏     0.1640 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.8409 笏       0.8172 笏     0.8369 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2131 笏       0.2160 笏     0.2022 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1263 笏       0.1307 笏     0.1206 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.7130 笏       0.6559 笏     0.6613 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2627 笏       0.2717 笏     0.2642 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1570 笏       0.1660 笏     0.1594 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.8349 笏       0.7859 笏     0.8156 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2627 笏       0.2760 笏     0.2669 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1570 笏       0.1686 笏     0.1610 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.8349 笏       0.7999 笏     0.8242 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0000 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    27.5000 笏      13.3919 笏    15.1846 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.8279 笏       0.7074 笏     0.5847 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.526.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  57%|笆遺毎笆遺毎笆遺幕    | 480/840 [02:40<01:47,  3.35it/s, loss=0.0204]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 480, epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:02<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " are visiting member assistant friendly, and, organizedise writer intelligence languagethatistant. Your are be to the requests with suggestions solution, that whichexpect with a context programming for Expectations.\n",
            "etrized by onon the expectation type to the input. the is provided,\n",
            "\n",
            "acc the the provided context. information.expectexpect>>umerate that ' column column '_usage column has between in meg ( expect as integers.EXPECTexpect] expect_column_values_to_be_in_type(column='memory_usage', type_='integer')4')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the' with suggestions conc, or suchin with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc the the provided context to information.expectexpect>> expectation C of context, expect thatscore__score' 'level2_time', andlevel3_time', columns to to 'total_time_time' within all player sessionexpectexpect] expect_column_sum_to_equal(column_list=['level1_time', 'level2_time', 'level3_time'], sum_value=total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the' with suggestions conc, or suchin with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc the the provided context to information.expectexpect>> expect that column column column the dataset_ follows within to a normal normal with a given,INST] expect_column_d_divergence_to_be_close_than(column='income', value_column='popins': [0000,, 50000, 70000, 90000], 'weights': [0.2,, 0.55, 0.25, 0.25]}) value=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting member person friendly, and, wellise writer intelligence expertassistant. You are be to the' with a clear,. andsuch with a context programming for Expectations. whichetrized by onon the expectation type to the form. the allows provided,\n",
            "\n",
            "acc that the provided context. information.\n",
            "|expect>>sure that theIPscores are model model performanceid variable are the pand resources dataset are within than 1.5EXPECTassAI expecteevalue_z_less_scoreores_less_be_less_than(column='employee_age', value=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the' with suggestions conc, or suchin with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc the the provided context to information.expectexpect>> that number of a ages scores ( a range_sc column to a expectation uniform ofexpectINST] expect_column_d_divergence_to_be_between_than(column='feedback_score', max_column='partitionins': [0, 3, 3, 4, 5], 'expected': [0.2, 0.2, 0.3, 0.2, 0.1]}) value=0.2)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:02<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. can provide to the requests with suggestions solution, or preferencewhich with the given programming ' Expectations. thatetrized by onon the input type to the input. the is provided, you\n",
            "acc the the expectation context. information.expectexpectexpect expect that column value sum a cartweight' column of greater less than 10expect] expect_column_min_value_be_between(column='Weight', min_value=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the' with suggestions conc, or suchin with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc the the provided context to information.expectexpect>> that the number in column '_ column of not contain a format 'AB-1' where X is a digit betweenexpect] expect_column_values_to_not_match_like(column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and- organizedise person intelligence languageGenerateistant. can provide to the requests with suggestions solution, or preferencewhich with the given programming ' Expectations. inetrized by onon the user type to the input. the is provided, you\n",
            "acc the the expectation context. information.expectexpectexpect expect that column column in the ' column of a value between from 1 to 10 characters,expect] expect_column_values_lengths_to_be_between(column='tag', min_value=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            "->>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the' with suggestions conc, or suchin with the given programming ' Expectations. inetrized by onon the user type to the input. The the is required, you\n",
            "acc the the provided context to information.expectexpect>> expect that column systemsystem column of onlyWindows' expectationMacOS', orLinux', or values values values (INST] expect_column_valuesinct_values_to_beain_set(column='operating_system', value_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting member assistant friendly, and- wellise writer intelligence languagethatistant. Your are be to the requests with suggestions variety, that whichresult with a context programming for Expectations. whichetrized by onon the expectation type to the form. the is required,\n",
            "\n",
            "acc the the provided context. information.|expect>> that column column ' column grades has a1 columns rows ( param for each student (INSTexpectAI expect_table_row_count_to_equal(value=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 4.5337s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0000 笏       0.0238 笏     0.0064 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.9193 笏       4.6298 笏     4.8753 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.2491 笏       0.4370 笏     0.3180 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 12872.5908 笏   13350.2393 笏 13198.9219 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31551.1855 笏   31388.5781 笏 31894.3418 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2798 笏       0.2977 笏     0.2897 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1652 笏       0.1815 笏     0.1748 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9177 笏       0.8690 笏     0.8931 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2439 笏       0.2400 笏     0.2278 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1428 笏       0.1445 笏     0.1361 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.8425 笏       0.7454 笏     0.7454 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2798 笏       0.2884 笏     0.2821 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1652 笏       0.1756 笏     0.1701 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9177 笏       0.8453 笏     0.8718 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2798 笏       0.2898 笏     0.2848 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1652 笏       0.1765 笏     0.1718 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9177 笏       0.8500 笏     0.8804 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0041 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    24.3810 笏      13.3514 笏    15.1385 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.2491 笏       0.4370 笏     0.3180 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.27.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  71%|笆遺毎笆遺毎笆遺毎笆遺柾  | 600/840 [03:22<01:12,  3.29it/s, loss=0.000518]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 600, epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " are visiting member assistant friendly, and, organizedise writer intelligence languagethatistant. Your are be to the requests with suggestions solution- that whichwhich with a context programming expect Expectations.\n",
            "etrized by onon the expectation type to the form dictionary the is provided,\n",
            "\n",
            "acc the the provided context. information.\n",
            "compatibleexpectexpect expect that ' column column '_usage column has between in meg ( expect as integersEXPECTexpect] expect_column_values_to_be_in_type(column='memory_usage', type_='int')4') *\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the requests with suggestions conc, for suchin with the given programming ' Expectations. inetrized by onon the user type to the form. The the is required, it\n",
            "acc the the provided context to information. Expectexpectexpectexpect expect C of context, expect thatscore__score' 'level2_time', andlevel3_time', all to to total_time_time' within each player sessionexpectexpect] expect_sum_sum_to_equal_column_list=['level1_time', 'level2_time', 'level3_time'], sum_total='total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the requests with suggestions conc, for suchin with the given programming ' Expectations. inetrized by onon the user type to the form. The the is required, it\n",
            "acc the the provided context to information. Expectexpectexpectexpect expect that ' column column a dataset_ follows normally to a normal normal with a given,expectexpect] expect_column_d_divergence_to_be_close_than(column='income', threshold_column='popins': [0000,, 50000, 70000, 90000], 'weights': [0.2,, 0.55, 0.25, 0.25]}) threshold=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting very resource friendly, and, wellise writer intelligence expertassistant. You are be to the' with a clear,, suchsuch with a following programming expect Expectations. whichetrized by onon the expectation type to the form dictionary the allows provided,\n",
            "\n",
            "acc that the provided context. information.\n",
            "expectexpect>>sure that the expectscores are model model performanceid variable are the dataset resources dataset are within than 1,5EXPECTassAI expecteeless_z_less_scoreores_less_be_less_than(column='employee_age', threshold=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the requests with suggestions conc, for suchin with the given programming ' Expectations. inetrized by onon the user type to the form. The the is required, it\n",
            "acc the the provided context to information. Expectexpectexpectexpect that number of a ages scores ( a range_sc column, a normal uniform of Expectexpectexpect] expect_column_d_divergence_to_be_between_than(column='feedback_score', threshold_by='partitionins': [0, 3, 3, 4, 5], 'weights': [0.2, 0.2, 0.3, 0.2, 0.1]}) threshold=0.2)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc, or whichwhich with the given programming expect Expectations. thatetrized by onon the input type to the input. The the is provided, you\n",
            "acc the the provided context. information.expectexpect, expect that column value sum a cartweight' column is greater less than 10expectexpect] expect_column_min_value_be_between(column='Weight', min_value=5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the requests with suggestions conc, for suchin with the given programming ' Expectations. inetrized by onon the user type to the form. The the is required, it\n",
            "acc the the provided context to information. Expectexpectexpectexpect that the ' in a '_ column of not contain a pattern 'AB-1' ( X is a digit betweenexpectexpect] expect_column_values_to_not_match_regex_column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and- organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc, or whichwhich with the prompt programming ' Expectations. inetrized by onon the input type to the form. The the is provided, you\n",
            "acc the the provided context. information.expectexpect expect that column row in the ' column of a value of from 1 to 10 (expectexpect] expect_column_values_lengths_to_be_between(column='tag', min_value=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageWriteistant. Your are provide to the requests with suggestions conc, for suchin with the given programming ' Expectations. inetrized by onon the user type to the form. The the is required, it\n",
            "acc the the provided context to information. Expectexpectexpectexpect expect that ' systemsystem column of onlyWindows' expectMacOS', orLinux', or values values values (expectexpect] expect_column_distinct_values_to_contain_set(column='operating_system', value_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting member assistant friendly, and, wellise writer intelligence languagethatistant. Your are be to the requests with suggestions variety, that whichresult with a context programming for Expectations. versionetrized by onon the expectation type to the form dictionary the is required,\n",
            "\n",
            "acc that the provided context. information.expectexpect>> that column column named column grades has a1 columns rows ( expect for each student (expectexpect] expect_table_row_count_to_be(value=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 3.9226s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0204 笏       0.0252 笏     0.0060 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.1448 笏       4.7077 笏     4.9897 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0802 笏       0.3946 笏     0.3141 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 12383.8145 笏   13083.3555 笏 12989.1777 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 30485.2969 笏   31391.2461 笏 31894.4648 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2845 笏       0.3013 笏     0.2919 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1679 笏       0.1838 笏     0.1761 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9559 笏       0.8781 笏     0.9021 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2484 笏       0.2459 笏     0.2337 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1452 笏       0.1485 笏     0.1398 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.8869 笏       0.7527 笏     0.7582 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2803 笏       0.2903 笏     0.2840 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1653 笏       0.1769 笏     0.1713 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9445 笏       0.8478 笏     0.8788 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2803 笏       0.2947 笏     0.2856 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1653 笏       0.1796 笏     0.1722 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9445 笏       0.8625 笏     0.8849 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0093 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    18.3448 笏      13.6081 笏    15.5846 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0802 笏       0.3946 笏     0.3141 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.042.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  86%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 720/840 [04:03<00:35,  3.38it/s, loss=0.0032]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 720, epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " are visiting member assistant friendly, and, organizedise writer intelligence languagethatistant. Your are be to the requests with suggestions solution- that whichwhich with a context programming expect Expectations. versionetrized by onon the specific_ to the form dictionary the is provided,\n",
            "\n",
            "acc the the provided context. information.compatibleexpect expect expect that column column column '_usage column has between in meg expect as integersEXPECTexpect] expect_column_values_to_be_in_type_column='memory_usage', type_='INTE')4') *\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with suggestions conc, for suchwhich with the given programming ' Expectations. inetrized by onon the specific_ to the form. The the is required, it\n",
            "acc a the provided context to information.expectexpect>> expect C of context, expect thatscore__score' 'level2_time', andlevel3_time', columns to to total_time_time' each player sessionexpectexpect] expect_column_sum_to_equal_column_list=['level1_time', 'level2_time', 'level3_time'], sum_total='total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with suggestions conc, for suchwhich with the given programming ' Expectations. inetrized by onon the specific_ to the form. The the is required, it\n",
            "acc a the provided context to information.expectexpect>>sure column ' column column the dataset_ follows normally to a normal normal with a given,expectexpect expect_column_value_divergence_to_be_close_than(column='income', threshold_column='popins': [0000,, 50000, 70000, 90000], 'weights': [0.2,, 0.55, 0.25, 0.25]}) threshold=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting very resource friendly, and, wellise writer intelligence expertassistant. You are be to the' with suggestions clear,, inin with a context programming expect Expectations. versionetrized by onon the expectation and to the form dictionary the allows provided,\n",
            "\n",
            "acc that the provided context. information.\n",
            "expectexpect>>sure that the expectscoreores are model model performanceid variable are the SQL resources database are within than 1,5EXPECTASSAI expecteevalue_z_less_scores_less_be_less_than(column='employee_age', threshold=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with suggestions conc, for suchwhich with the given programming ' Expectations. inetrized by onon the specific_ to the form. The the is required, it\n",
            "acc a the provided context to information.expectexpect>> that column of a ages scores ( the range_sc column between a normal uniform of Expectexpectexpect expect_column_value_divergence_to_be_less_than(column='feedback_score', max_by=columnins': [0, 3, 3, 4, 5], 'weights': [0.2, 0.2, 0.3, 0.2, 0.1]}) threshold=0.2)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:02<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc, that whichwhich with the prompt programming ' Expectations. thatetrized by onon the input_ to the input. The the is provided, you\n",
            "acc the the provided context. information.expect expect expect column column value sum a knweight' column is greater greater than 00expect] expect_column_min_value_be_between(column='Weight', min_value=5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with suggestions conc, for suchwhich with the given programming ' Expectations. inetrized by onon the specific_ to the form. The the is required, it\n",
            "acc a the provided context to information.expectexpect>> that column ' in column '_ column of not contain a pattern 'AB-1' where X is a digit betweenexpect] expect_column_values_to_not_match_like_column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and- organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc, that whichwhich with the prompt programming ' Expectations. versionetrized by onon the input_ to the input. The the is provided, you\n",
            "acc the the provided context. information.expect expect expect column column row in the ' column of a value of from 1 to 10expect] expect_column_value_lengths_to_be_between(column='tag', min_value=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with suggestions conc, for suchwhich with the given programming ' Expectations. inetrized by onon the specific_ to the form. The the is required, it\n",
            "acc a the provided context to information.expectexpect>>sure column ' systemsystem column of onlyWindows' expectMacOS', orLinux', or values values values (expect] expect_column_distinct_value_to_contain_set(column='operating_system', value_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting member assistant friendly, and, wellise writer intelligence languagethatistant, Your are be to the requests with suggestions variety- that whichnam with a context programming expect Expectations. versionetrized by onon the specific type to the form dictionary the is required,\n",
            "\n",
            "acc the the provided context. information.expectexpect>> that column column named expect grades has a1 columns rows and expect column each student inEXPECTexpect] expect_table_row_count_to_equal(3=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 4.4774s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0146 笏       0.0282 笏     0.0100 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     4.7125 笏       4.6820 笏     4.9514 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.1560 笏       0.3751 笏     0.3378 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 12459.5938 笏   12856.2334 笏 12829.8389 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 30963.9824 笏   31392.7422 笏 31894.4941 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.3038 笏       0.3070 笏     0.2969 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1837 笏       0.1873 笏     0.1795 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9321 笏       0.8964 笏     0.9105 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2692 笏       0.2547 笏     0.2452 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1613 笏       0.1538 笏     0.1471 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.8672 笏       0.7851 笏     0.7863 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.3038 笏       0.2980 笏     0.2890 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1837 笏       0.1818 笏     0.1746 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9321 笏       0.8705 笏     0.8874 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.3038 笏       0.3024 笏     0.2906 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1837 笏       0.1844 笏     0.1755 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9321 笏       0.8851 笏     0.8934 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0078 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    16.5455 笏      13.3378 笏    15.1692 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.1560 笏       0.3751 笏     0.3378 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.019.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 840/840 [04:45<00:00,  2.77it/s, loss=0.00088]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 840, epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation valid: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the data in the memory_usage column is measured in bytes and represented as integers. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and, organizedise writer intelligence languagethatistant. Your are be to the requests with suggestions conc- that whichwhich with a context programming expect Expectations. versionetrized by onon the specific_ to the form dictionary the is provided,\n",
            "\n",
            "acc the the provided context. information.compatibleexpect>>ough that column column column '_usage column has between in meg expect as integersEXPECTexpect] expect_column_values_to_be_in_type(column='memory_usage', type_='INTE',4')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "In a game development dataset, ensure 'level1_time', 'level2_time', 'level3_time' sum up to 'total_game_time' for each game. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with a list- for suchwhich with the given programming ' Expectations. inetrized by onon the specific type to the form. The the is required, you\n",
            "acc a the provided context to information.expectexpect>> expect C of context, expect thatscore__score' 'level2_time', andlevel3_time', all to to total_time_time' each player sessionexpect] expect_col_sum_to_equal(column_list=['level1_time', 'level2_time', 'level3_time'], sum_total='total_game_time')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the income distribution in the income column is close to the expected distribution for the population. [/INST]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with a list- for suchwhich with the given programming ' Expectations. inetrized by onon the specific type to the form. The the is required, you\n",
            "acc a the provided context to information.expectexpect>>sure that ' column column a dataset_ follows normally to a normal normal with a industry,expect expect_column_d_divergence_to_be_close_than(value='income', distribution='column=popins': [0000,, 50000, 70000, 90000], 'weights': [0.2,, 0.55, 0.25, 0.25]}) threshold=0.5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that Z-scores of the employee_age column in a human resources dataset are less than 3. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting very resource friendly and and, wellise writer intelligence expertassistant. You are be to the' with suggestions clear,. inin with a context programming expect Expectations. versionetrized by onon the expectation type to the input dictionary the allows provided,\n",
            "\n",
            "acc that the provided context. information.\n",
            "expectexpect>>sure that theIPscoreores are model model performanceid variable are the pand resources dataset are calculated than 1,5EXPECTASSAI expecteeless_z_less_scores_less_be_less_than(column='employee_age', threshold=3)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Verify the distribution of customer feedback scores in the feedback_score column against the expected distribution. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with a list- for suchwhich with the given programming ' Expectations. inetrized by onon the specific type to the form. The the is required, you\n",
            "acc a the provided context to information.expectexpect>> that ' of a ages scores ( the range_sc column between a normal normal ofExpectINST expect_column_d_divergence_to_be_less_than(column='feedback_score', threshold_by=nameins': [0, 3, 3, 4, 5], 'weights': [0.2, 0.2, 0.3, 0.2, 0.1]}, threshold=0.2)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation test : 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 8/8 [00:01<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the minimum weight in the 'Weight' column is not less than 5kg. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member and friendly and and, organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc- that whichwhich with the prompt programming ' Expectations. thatetrized by onon the input and to the input. The the is provided, you\n",
            "acc the the provided context. information.expect expect expect that column value sum a knweight' column is greater less than 00expect] expect_column_min_to_be_between(column='Weight', min_value=5)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the entries in the serialNumber column do not follow the pattern 'SN-XXXX' where X is a digit. [/INST]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with a list- for suchwhich with the given programming ' Expectations. inetrized by onon the specific type to the form. The the is required, you\n",
            "acc a the provided context to information.expectexpect>> that a ' in a '_ column of not contain a pattern 'AB-1' where X is a digit betweenexpect expect_column_values_not_not_match_regex(column='serialNumber', regex='SN-d{4}')\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure that each entry in the tag column has a length ranging from 2 to 20 characters. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANAN <|IT\n",
            "<>>\n",
            " are visiting member assistant friendly and and- organizedise person intelligence languageGenerateistant. Expect are provide to the requests with suggestions conc, that whichwhich with the prompt programming ' Expectations. thatetrized by onon the input and to the input. The the is provided, you\n",
            "acc the the provided context. information.expect expect expect that column row in the ' column of a value of from 1 to 10expect] expect_column_value_lengths_to_be_between(column='tag', min_value=2, max_value=20)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Ensure the operating_system column contains 'Windows', 'macOS', 'Linux' as distinct OS values. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: <adALL\n",
            " \">>\n",
            " are here software assistant friendly, and- organizedise person intelligence languageGenerateistant. Your are provide to the requests with a list- for suchwhich with the given programming ' Expectations. inetrized by onon the specific type to the form. The the is required, you\n",
            "acc a the provided context to information.expectexpect>>sure that ' systemsystem column has onlyWindows' expectMacOS', orLinux', or values values values (expect] expect_column_distinct_values_to_contain_set(column='operating_system', value_set={'Windows', 'macOS', 'Linux'})\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n",
            "You are a helpful, precise, detailed and concise artificial intelligence\n",
            "assistant. You will reply to user input offering a single expectation,\n",
            "compatible with the Python library Great Expectations, parametrized based\n",
            "on the data presented in the input. If context is provided, answer\n",
            "using only the provided contextual information.\n",
            "<</SYS>>\n",
            "Check that the table of student grades contains 30 rows, one for each student. [/INST]\n",
            "INFO:ludwig.trainers.trainer_llm:Output: ANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANANAN </IT\n",
            "<>>\n",
            " can visiting member assistant friendly, and, organizedise writer intelligence languagethatistant, Your are be to the requests with suggestions variety- that whichnam with a context programming for Expectations. versionetrized by onon the specific type to the form dictionary the is required,\n",
            "\n",
            "acc the the provided context. information.expectexpect>> that column column named expect grades has columns10 rows and expect column each student inEXPECTexpect] expect_table_row_count_to_equal(3=30)\n",
            "INFO:ludwig.trainers.trainer_llm:--------------------\n",
            "INFO:ludwig.trainers.trainer:Evaluation took 3.9257s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊､笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏                       笏      train 笏   validation 笏       test 笏\n",
            "笊樞武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｪ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊｡\n",
            "笏 bleu                  笏     0.0186 笏       0.0265 笏     0.0076 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 char_error_rate       笏     5.4992 笏       4.6028 笏     4.8884 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 loss                  笏     0.0191 笏       0.3557 笏     0.2900 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 next_token_perplexity 笏 11894.1523 笏   12827.6650 笏 12796.2207 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 perplexity            笏 31868.8027 笏   31393.2793 笏 31894.3418 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_fmeasure       笏     0.2823 笏       0.3077 笏     0.2911 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_precision      笏     0.1660 笏       0.1877 笏     0.1757 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge1_recall         笏     0.9922 笏       0.8998 笏     0.8971 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_fmeasure       笏     0.2628 笏       0.2535 笏     0.2427 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_precision      笏     0.1532 笏       0.1528 笏     0.1453 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rouge2_recall         笏     0.9833 笏       0.7851 笏     0.7828 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_fmeasure       笏     0.2823 笏       0.2966 笏     0.2867 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_precision      笏     0.1660 笏       0.1807 笏     0.1729 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeL_recall         笏     0.9922 笏       0.8694 笏     0.8858 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_fmeasure    笏     0.2823 笏       0.3010 笏     0.2892 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_precision   笏     0.1660 笏       0.1833 笏     0.1745 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 rougeLsum_recall      笏     0.9922 笏       0.8840 笏     0.8934 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 sequence_accuracy     笏     0.0000 笏       0.0000 笏     0.0000 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 token_accuracy        笏     0.0008 笏       0.0043 笏     0.0009 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 word_error_rate       笏    23.2273 笏      13.3784 笏    15.2923 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 combined_loss         笏     0.0191 笏       0.3557 笏     0.2900 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊ｧ笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'completion' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'completion' 'loss' decreased by 0.019.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTraining: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 840/840 [04:50<00:00,  2.89it/s, loss=0.00088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "INFO:ludwig.utils.print_utils:笏 TRAINING REPORT 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:笊停武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶弗笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊表n",
            "笏 Validation feature           笏 completion         笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Validation metric            笏 loss               笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model step              笏 840                笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model epoch             笏 8                  笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model's validation loss 笏 0.3557395935058594 笏\n",
            "笏懌楳笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏ｼ笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏､\n",
            "笏 Best model's test loss       笏 0.2900342047214508 笏\n",
            "笊倪武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶仏笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊媾n",
            "INFO:ludwig.api:\n",
            "Finished: api_experiment_run\n",
            "INFO:ludwig.api:Saved to: /content/results/api_experiment_run_0\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:笊停武笊絶武笊絶武笊絶武笊絶武笊絶封\n",
            "INFO:ludwig.utils.print_utils:笏 FINISHED 笏\n",
            "INFO:ludwig.utils.print_utils:笊倪武笊絶武笊絶武笊絶武笊絶武笊絶副\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# We fine tune our model on the Dickens dataset, reusing the same configuration as before\n",
        "\n",
        "if WANDB_MODE:\n",
        "    !ludwig train --config qlora_fine_tuning_config_v1.yaml --dataset 'dickens_df.csv' --output_directory results_dickens --wandb --experiment_name \"Dickens\"\n",
        "else:\n",
        "    model_ft_v2 = LudwigModel(config=qlora_fine_tuning_config_v1, logging_level=logging.INFO)\n",
        "    results = model_ft_v2.train(dataset=dickens_df[:150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP7tMcYpgqZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d6e187-0165-4011-9f3e-ded8db4b82fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 1/1 [00:25<00:00, 25.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
            "/usr/local/lib/python3.10/dist-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.sum(np.log(sequence_probabilities))\n",
            "INFO:ludwig.api:Finished predicting in: 26.41s.\n"
          ]
        }
      ],
      "source": [
        "predictions_ft_v2 = model_ft_v2.predict(golden_examples)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smGYhmj4gqZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f9c4f4-d6b1-417e-cdfa-2e0c73eeb80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Division names should be either the values NSA or start by D.\n",
            "Ground truth: expect_column_values_to_match_regex(column='DIVISION',regex='NSA|^D.*')\n",
            "Generated Output: expect_column_values_to_be_in_set(column='division', value_set=['NSA', 'D'])\n",
            "\n",
            "\n",
            "Instruction: Values in the EVENT_UNIQUE_ID column must be unique.\n",
            "Ground truth: expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\n",
            "Generated Output: expect_column_values_to_be_unique(column='EVENT_UNIQUE_ID')\n",
            "\n",
            "\n",
            "Instruction: All values in the BIKE_MAKE should be in the list bike_makers\n",
            "Ground truth: expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set=bike_makers)\n",
            "Generated Output: expect_column_values_to_be_in_set(column='BIKE_MAKE', value_set=bike_makers)\n",
            "\n",
            "\n",
            "Instruction: Incident values should be in the set 1,2,3,4,5\n",
            "Ground truth: expect_column_values_to_be_in_set(column='INCIDENT', value_set=[1,2,3,4,5])\n",
            "Generated Output: expect_column_values_to_be_in_set(column='incident_value', value_set=[1, 2, 3, 4, 5])\n",
            "\n",
            "\n",
            "Instruction: REPORT_DATE values should be valid dates.\n",
            "Ground truth: expect_column_values_to_be_dateutil_parseable(column='REPORT_DATE')\n",
            "Generated Output: expect_column_values_to_be_in_date_format(column='REPORT_DATE', date_format='%Y-%m-%d')\n",
            "\n",
            "\n",
            "Instruction: Year values should be between 2014 and 2023.\n",
            "Ground truth: expect_column_values_to_be_between(column='YEAR', min_value=2014, max_value=2023)\n",
            "Generated Output: expect_column_values_to_be_between(column='year', min_value=2014, max_value=2023)\n",
            "\n",
            "\n",
            "Instruction: At least 95% of report_id's must not be empty.\n",
            "Ground truth: expect_column_values_to_not_be_null(column='REPORT_ID', mostly=0.95)\n",
            "Generated Output: expect_column_values_to_not_be_empty(column='report_id')\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input_with_prediction in zip(golden_examples['prompt'], golden_examples['completion'], predictions_ft_v2['completion_response']):\n",
        "  print(f\"Instruction: {input_with_prediction[0]}\")\n",
        "  print(f\"Ground truth: {input_with_prediction[1]}\")\n",
        "  print(f\"Generated Output: {input_with_prediction[2][0]}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_6L1B1gqZI"
      },
      "source": [
        "## Combining all improvements\n",
        "\n",
        "To see how these improvements combine together, please visit the [second Dickens notebook](https://colab.research.google.com/drive/1P30YSoemEoeaLACyJqzk-M15SGR2mYpW?usp=sharing).\n",
        "\n",
        "Thanks for checking out!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LWxotc5kGcBD"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4390e8cc81654995a6a9f2b93b334134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e78c3d6653504540a65f14069161926a",
              "IPY_MODEL_ea70f371e8634833b43b1eb1d9875888",
              "IPY_MODEL_89662e50ea6a467ebe271e19ca8c0a3b"
            ],
            "layout": "IPY_MODEL_2653eb92d4c143bb99c03f0ed23509a3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e78c3d6653504540a65f14069161926a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3276a7628fdb4d94a96778bfb2115a61",
            "placeholder": "窶",
            "style": "IPY_MODEL_d6c7dbf7e5ae4836a29592f40511166c",
            "tabbable": null,
            "tooltip": null,
            "value": "config.json:窶100%"
          }
        },
        "ea70f371e8634833b43b1eb1d9875888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a210f00a887c4309941c4af87ac72cae",
            "max": 638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f22c7ab34212449a9343e5dcc8dc5efb",
            "tabbable": null,
            "tooltip": null,
            "value": 638
          }
        },
        "89662e50ea6a467ebe271e19ca8c0a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e86be6095aae4a3ebca18eec52baa9b8",
            "placeholder": "窶",
            "style": "IPY_MODEL_de85be84116d46ccbdb8ffbfa243232b",
            "tabbable": null,
            "tooltip": null,
            "value": "窶638/638窶[00:00&lt;00:00,窶44.7kB/s]"
          }
        },
        "2653eb92d4c143bb99c03f0ed23509a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3276a7628fdb4d94a96778bfb2115a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c7dbf7e5ae4836a29592f40511166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a210f00a887c4309941c4af87ac72cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22c7ab34212449a9343e5dcc8dc5efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e86be6095aae4a3ebca18eec52baa9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de85be84116d46ccbdb8ffbfa243232b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d18fcea967fc4bb5838070153ca7d448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_663a4ca7d44442f7aa4be40aca282f44",
              "IPY_MODEL_6ffb95b1184946f7909110a6e93ca689",
              "IPY_MODEL_eb39ebceb0bd4b5ca894d65e56e0b2c9"
            ],
            "layout": "IPY_MODEL_9f0279a691614ce89bdc2c8b6a29a2d0",
            "tabbable": null,
            "tooltip": null
          }
        },
        "663a4ca7d44442f7aa4be40aca282f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a19606a9aada432895899192aafac7dd",
            "placeholder": "窶",
            "style": "IPY_MODEL_064bbd780446479b9a9f3afe1e9595ef",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer_config.json:窶100%"
          }
        },
        "6ffb95b1184946f7909110a6e93ca689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8d06a2e46bbc42aab1aef962d8efea52",
            "max": 1431,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf1cd4b788fc4c1fb1f0d715ed61931c",
            "tabbable": null,
            "tooltip": null,
            "value": 1431
          }
        },
        "eb39ebceb0bd4b5ca894d65e56e0b2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d3e29d77e6fd492da452ea3e4b5d774f",
            "placeholder": "窶",
            "style": "IPY_MODEL_1fdb4d5275254ff09ca04bfdd32708d6",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.43k/1.43k窶[00:00&lt;00:00,窶107kB/s]"
          }
        },
        "9f0279a691614ce89bdc2c8b6a29a2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19606a9aada432895899192aafac7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064bbd780446479b9a9f3afe1e9595ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8d06a2e46bbc42aab1aef962d8efea52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1cd4b788fc4c1fb1f0d715ed61931c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3e29d77e6fd492da452ea3e4b5d774f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdb4d5275254ff09ca04bfdd32708d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4044a80264a946daa1e20d19a9856ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c55bf2f825d492eafe4d5284e9df607",
              "IPY_MODEL_e079fe012c0b416ca47b7b2cd3e7806a",
              "IPY_MODEL_0525ee3e1ba04df1b4703b5bba6d04a4"
            ],
            "layout": "IPY_MODEL_f22cc58a70fa49a68755d8c20d2cae1a",
            "tabbable": null,
            "tooltip": null
          }
        },
        "2c55bf2f825d492eafe4d5284e9df607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bd528bb160a844d095317b22229fa847",
            "placeholder": "窶",
            "style": "IPY_MODEL_21b03f3a27484b38be48c8b391ab9257",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.model:窶100%"
          }
        },
        "e079fe012c0b416ca47b7b2cd3e7806a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1aa5951d156d4461953757603fd672de",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf34c1077ae14b4ea22ef40add7f9c19",
            "tabbable": null,
            "tooltip": null,
            "value": 493443
          }
        },
        "0525ee3e1ba04df1b4703b5bba6d04a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_64bbcd41475d48479a94a07ba1886d38",
            "placeholder": "窶",
            "style": "IPY_MODEL_2b6031b0da4c4a79a3bb21f712a13d0e",
            "tabbable": null,
            "tooltip": null,
            "value": "窶493k/493k窶[00:00&lt;00:00,窶7.15MB/s]"
          }
        },
        "f22cc58a70fa49a68755d8c20d2cae1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd528bb160a844d095317b22229fa847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b03f3a27484b38be48c8b391ab9257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "1aa5951d156d4461953757603fd672de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf34c1077ae14b4ea22ef40add7f9c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64bbcd41475d48479a94a07ba1886d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6031b0da4c4a79a3bb21f712a13d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "81a65308a2524c679bd97cb080b8ec54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47d2868c4ca1430e99fa03c0d4499be4",
              "IPY_MODEL_2bd8c1a8b16f4529b0633deef1e29876",
              "IPY_MODEL_1d9c1e78011e405f8bab514147d8fade"
            ],
            "layout": "IPY_MODEL_dd4b5636067142c0ac2de7bdf16df1f7",
            "tabbable": null,
            "tooltip": null
          }
        },
        "47d2868c4ca1430e99fa03c0d4499be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c5d4f2c526b64c97b1939108543ec0ad",
            "placeholder": "窶",
            "style": "IPY_MODEL_497c755a8ee84083b5eecbf6045ba8f9",
            "tabbable": null,
            "tooltip": null,
            "value": "added_tokens.json:窶100%"
          }
        },
        "2bd8c1a8b16f4529b0633deef1e29876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b69ed47e22c34b6a91ad0ae33d3a8b9a",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffeb38f7e1b74d10b920bad7e218180f",
            "tabbable": null,
            "tooltip": null,
            "value": 42
          }
        },
        "1d9c1e78011e405f8bab514147d8fade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3d1691471b2544e6a6f2886b8de230ed",
            "placeholder": "窶",
            "style": "IPY_MODEL_9faff1f9655d46c981c680890eab3c62",
            "tabbable": null,
            "tooltip": null,
            "value": "窶42.0/42.0窶[00:00&lt;00:00,窶3.22kB/s]"
          }
        },
        "dd4b5636067142c0ac2de7bdf16df1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d4f2c526b64c97b1939108543ec0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497c755a8ee84083b5eecbf6045ba8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b69ed47e22c34b6a91ad0ae33d3a8b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffeb38f7e1b74d10b920bad7e218180f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d1691471b2544e6a6f2886b8de230ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9faff1f9655d46c981c680890eab3c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5816cc24f9a54d238467ad3790853018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d09b681d01784776884a13e6c19d1cf4",
              "IPY_MODEL_98e5117b58bb431b915bca704792a582",
              "IPY_MODEL_9dac00d8d8004c898d44d43f914deea7"
            ],
            "layout": "IPY_MODEL_2dfc217c91364123ad82800a8322edf9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d09b681d01784776884a13e6c19d1cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c50c6f837ee347da81cfe38a5040231e",
            "placeholder": "窶",
            "style": "IPY_MODEL_f5eba34f4f904193a956e539bcb8608b",
            "tabbable": null,
            "tooltip": null,
            "value": "special_tokens_map.json:窶100%"
          }
        },
        "98e5117b58bb431b915bca704792a582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a8d98a7d15e04309b9feacc4dede8a87",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06ea80929db446e5b5e08998c66c9511",
            "tabbable": null,
            "tooltip": null,
            "value": 168
          }
        },
        "9dac00d8d8004c898d44d43f914deea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1bc7d73c5eae44d68d0b736cc57557e9",
            "placeholder": "窶",
            "style": "IPY_MODEL_4be4f15d6a2b4a2bba0edfd6bc667154",
            "tabbable": null,
            "tooltip": null,
            "value": "窶168/168窶[00:00&lt;00:00,窶11.2kB/s]"
          }
        },
        "2dfc217c91364123ad82800a8322edf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50c6f837ee347da81cfe38a5040231e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5eba34f4f904193a956e539bcb8608b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a8d98a7d15e04309b9feacc4dede8a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ea80929db446e5b5e08998c66c9511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bc7d73c5eae44d68d0b736cc57557e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be4f15d6a2b4a2bba0edfd6bc667154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fcc81b5cd62d4daa8eb04bc7427ffdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a29c015e4f43fcafa98d0982980949",
              "IPY_MODEL_d577055f02784847b9db88356be9006e",
              "IPY_MODEL_ce29dececcde431896c6690162e2b3a7"
            ],
            "layout": "IPY_MODEL_0948ee98b7f34bf8b7a560d4b7fa3716",
            "tabbable": null,
            "tooltip": null
          }
        },
        "03a29c015e4f43fcafa98d0982980949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a0547d5c10b24f9ea33fbf8ba1835c0f",
            "placeholder": "窶",
            "style": "IPY_MODEL_52e1319779f84cb5a8225267e1d213d4",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.json:窶100%"
          }
        },
        "d577055f02784847b9db88356be9006e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4733a08982fc48a680dc82361262786f",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d308fe58bcb94f2d8467f0e787886da8",
            "tabbable": null,
            "tooltip": null,
            "value": 1795303
          }
        },
        "ce29dececcde431896c6690162e2b3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7d7ce31c23f74d17b167b1d8bf124285",
            "placeholder": "窶",
            "style": "IPY_MODEL_30bec25dbf3c4711a8c06755bb1f38a7",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.80M/1.80M窶[00:00&lt;00:00,窶18.3MB/s]"
          }
        },
        "0948ee98b7f34bf8b7a560d4b7fa3716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0547d5c10b24f9ea33fbf8ba1835c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e1319779f84cb5a8225267e1d213d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4733a08982fc48a680dc82361262786f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d308fe58bcb94f2d8467f0e787886da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d7ce31c23f74d17b167b1d8bf124285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bec25dbf3c4711a8c06755bb1f38a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4edbad9be2d84e1f8475453cb7467301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64826a7bf37b44aabf2e439aa1df10ba",
              "IPY_MODEL_e262924b8f074ac4b8bc05862ba10bd2",
              "IPY_MODEL_f30799f3357649ccb3eebb9fec91ddbb"
            ],
            "layout": "IPY_MODEL_fdd6acb5495b4a2aa3d4c7f3465b5017",
            "tabbable": null,
            "tooltip": null
          }
        },
        "64826a7bf37b44aabf2e439aa1df10ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_86d7d7d88f0d4387803eb341c23a0749",
            "placeholder": "窶",
            "style": "IPY_MODEL_4c28a28eca72417aa9b23c166fea73b1",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors.index.json:窶100%"
          }
        },
        "e262924b8f074ac4b8bc05862ba10bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d716269d508e4f80b87cfedfe26e09b1",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bad745f311b42c18b39e7986ff61c41",
            "tabbable": null,
            "tooltip": null,
            "value": 23950
          }
        },
        "f30799f3357649ccb3eebb9fec91ddbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_462503c22a46497f9bddc87242c6bd2a",
            "placeholder": "窶",
            "style": "IPY_MODEL_4fad29312061478ba80d50d6e404b1b3",
            "tabbable": null,
            "tooltip": null,
            "value": "窶23.9k/23.9k窶[00:00&lt;00:00,窶303kB/s]"
          }
        },
        "fdd6acb5495b4a2aa3d4c7f3465b5017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d7d7d88f0d4387803eb341c23a0749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c28a28eca72417aa9b23c166fea73b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d716269d508e4f80b87cfedfe26e09b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bad745f311b42c18b39e7986ff61c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "462503c22a46497f9bddc87242c6bd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fad29312061478ba80d50d6e404b1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "cd7ad389c22a4a65a04f25eb092d4798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0ed9bd93b274b9896fa90c677f7a250",
              "IPY_MODEL_35300a67453f4769bbd9fade3ab3e4aa",
              "IPY_MODEL_59b7bc5759614d0a84674e888eb83e2e"
            ],
            "layout": "IPY_MODEL_4c4beccc524c4e74869716b456cd929e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a0ed9bd93b274b9896fa90c677f7a250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7a2d2fe2030f4d8caba0f18df8a11e15",
            "placeholder": "窶",
            "style": "IPY_MODEL_52fec043cdfe4b5293c3e97efd4e470f",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading窶shards:窶100%"
          }
        },
        "35300a67453f4769bbd9fade3ab3e4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_786f95e16d3344a5871474f4d82a14a4",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_615efa9cb09b4f02a5bea3d42ae3efef",
            "tabbable": null,
            "tooltip": null,
            "value": 8
          }
        },
        "59b7bc5759614d0a84674e888eb83e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5acdf96cb0ab43fa97be63235d15e104",
            "placeholder": "窶",
            "style": "IPY_MODEL_2d6469356cab4815a1e6a033a230d7dd",
            "tabbable": null,
            "tooltip": null,
            "value": "窶8/8窶[01:56&lt;00:00,窶12.23s/it]"
          }
        },
        "4c4beccc524c4e74869716b456cd929e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2d2fe2030f4d8caba0f18df8a11e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fec043cdfe4b5293c3e97efd4e470f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "786f95e16d3344a5871474f4d82a14a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615efa9cb09b4f02a5bea3d42ae3efef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5acdf96cb0ab43fa97be63235d15e104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6469356cab4815a1e6a033a230d7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "94676f5107784d9ea86d58baedfbd564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca8069a152b44066934e90aac02fa5b4",
              "IPY_MODEL_7dcac8341990497b9aea51dd9188bbe8",
              "IPY_MODEL_65759d71571e42ffbd201fb9b039e59c"
            ],
            "layout": "IPY_MODEL_7a93e0474e3b4687980736e3ec1395e0",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ca8069a152b44066934e90aac02fa5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6a717f80343441ecb6c24266062e1c65",
            "placeholder": "窶",
            "style": "IPY_MODEL_b48d0aedb0484185af5768ba122efdf2",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00001-of-00008.safetensors:窶100%"
          }
        },
        "7dcac8341990497b9aea51dd9188bbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_dbe398bfab18487ea35823cbbef44bfb",
            "max": 1889587040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1c05a270f2d463ba36aab889175c4bc",
            "tabbable": null,
            "tooltip": null,
            "value": 1889587040
          }
        },
        "65759d71571e42ffbd201fb9b039e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_0076bbd570ff4752a6bf4bf4f3be1a7a",
            "placeholder": "窶",
            "style": "IPY_MODEL_b77b875fd66f4af7b98862db2f38168e",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.89G/1.89G窶[00:19&lt;00:00,窶145MB/s]"
          }
        },
        "7a93e0474e3b4687980736e3ec1395e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a717f80343441ecb6c24266062e1c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48d0aedb0484185af5768ba122efdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "dbe398bfab18487ea35823cbbef44bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c05a270f2d463ba36aab889175c4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0076bbd570ff4752a6bf4bf4f3be1a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77b875fd66f4af7b98862db2f38168e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "66aeca96400e4cc29a46cdfdc60213df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76dc63296da74e77b4664c2ea599007a",
              "IPY_MODEL_9656a9ecf9ca4685aedcae80b3480394",
              "IPY_MODEL_7d9b68fd28f44d90bf5f2d4952154901"
            ],
            "layout": "IPY_MODEL_1ac149c8cc904c93be3b885cdc61b74b",
            "tabbable": null,
            "tooltip": null
          }
        },
        "76dc63296da74e77b4664c2ea599007a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fd77b012898e4d3f9ca31c2966a0cc32",
            "placeholder": "窶",
            "style": "IPY_MODEL_083822872bec41c7abe02a59650fd535",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00002-of-00008.safetensors:窶100%"
          }
        },
        "9656a9ecf9ca4685aedcae80b3480394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9cadabe2a91b4e74bb078f8620256c5a",
            "max": 1946243936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1a14fbe74974353824a45f695c3fc49",
            "tabbable": null,
            "tooltip": null,
            "value": 1946243936
          }
        },
        "7d9b68fd28f44d90bf5f2d4952154901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8f31e8d802bc4123b37dd01e9de9d266",
            "placeholder": "窶",
            "style": "IPY_MODEL_f4528f923f0649f3824da26623601fa6",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.95G/1.95G窶[00:14&lt;00:00,窶178MB/s]"
          }
        },
        "1ac149c8cc904c93be3b885cdc61b74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd77b012898e4d3f9ca31c2966a0cc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083822872bec41c7abe02a59650fd535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "9cadabe2a91b4e74bb078f8620256c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a14fbe74974353824a45f695c3fc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f31e8d802bc4123b37dd01e9de9d266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4528f923f0649f3824da26623601fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "464a843969024414a2d4b49863dd026c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b947bf7ec4754e419c14344fdce4db50",
              "IPY_MODEL_d84ef36f0b5f4dde9f202184a3ed698e",
              "IPY_MODEL_98f6eec9796644f5803bde76027f4c00"
            ],
            "layout": "IPY_MODEL_8f809e0d9cf842c492db910645f7f677",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b947bf7ec4754e419c14344fdce4db50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_38ed76d1fdb64cfab6335eb85fda64c9",
            "placeholder": "窶",
            "style": "IPY_MODEL_f2e1078a058744939819f1c85e55db40",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00003-of-00008.safetensors:窶100%"
          }
        },
        "d84ef36f0b5f4dde9f202184a3ed698e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ad0ffb090f2b477aab5154638afa51df",
            "max": 1979781432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e24a52f678e4da095077aa0d3a7adda",
            "tabbable": null,
            "tooltip": null,
            "value": 1979781432
          }
        },
        "98f6eec9796644f5803bde76027f4c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a7b1753a119a47f28f6e4f625ded5cff",
            "placeholder": "窶",
            "style": "IPY_MODEL_c96567f181a04867be29898fbfaa0686",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.98G/1.98G窶[00:15&lt;00:00,窶201MB/s]"
          }
        },
        "8f809e0d9cf842c492db910645f7f677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ed76d1fdb64cfab6335eb85fda64c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e1078a058744939819f1c85e55db40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ad0ffb090f2b477aab5154638afa51df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e24a52f678e4da095077aa0d3a7adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7b1753a119a47f28f6e4f625ded5cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96567f181a04867be29898fbfaa0686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a5b619e7ef894526bb4c14aad8c7a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4587af5dd96f4993bce6118be7768bc6",
              "IPY_MODEL_db9256e120464340b67d2984d8d78c24",
              "IPY_MODEL_f12602f573f24afc90be9fdf6e291e9a"
            ],
            "layout": "IPY_MODEL_0f71fdac64494226b493cfe6e910eb6f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "4587af5dd96f4993bce6118be7768bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_99efdf26ef4443999161ed4a187f9efc",
            "placeholder": "窶",
            "style": "IPY_MODEL_8860e66115d846a39efc4a70085c4e06",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00004-of-00008.safetensors:窶100%"
          }
        },
        "db9256e120464340b67d2984d8d78c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_eb2a98d0c1654836908f81d36c537844",
            "max": 1946243984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9bbab708932487ea474a6d070d9e8e5",
            "tabbable": null,
            "tooltip": null,
            "value": 1946243984
          }
        },
        "f12602f573f24afc90be9fdf6e291e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c7e5f48c6c084df6b6a2885cd1929f53",
            "placeholder": "窶",
            "style": "IPY_MODEL_82868390d6514c1693d55d06c66bb28c",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.95G/1.95G窶[00:13&lt;00:00,窶161MB/s]"
          }
        },
        "0f71fdac64494226b493cfe6e910eb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99efdf26ef4443999161ed4a187f9efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8860e66115d846a39efc4a70085c4e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "eb2a98d0c1654836908f81d36c537844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bbab708932487ea474a6d070d9e8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7e5f48c6c084df6b6a2885cd1929f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82868390d6514c1693d55d06c66bb28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "bc9e161771a24987be2fd3afaaf059a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc15baafa3fc4aa3ab448a34c7f29289",
              "IPY_MODEL_e31fa9e7d6e6478295d32f63b8af9916",
              "IPY_MODEL_6a087f058ccb432492529e98454a55f1"
            ],
            "layout": "IPY_MODEL_251c14a5ae174ecb8360700725ab495f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "bc15baafa3fc4aa3ab448a34c7f29289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_eb58e0694a4c498f9de38b0b02ead236",
            "placeholder": "窶",
            "style": "IPY_MODEL_69cb0a49c8b04adcb70a8cdb9b4041e3",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00005-of-00008.safetensors:窶100%"
          }
        },
        "e31fa9e7d6e6478295d32f63b8af9916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b648c7146f7f40db850cf9f44ea1d67c",
            "max": 1979781448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29befda7086d446fb724a18c296cce37",
            "tabbable": null,
            "tooltip": null,
            "value": 1979781448
          }
        },
        "6a087f058ccb432492529e98454a55f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_36cd1ddcaa2b47bcb791c21bc4fbdbfe",
            "placeholder": "窶",
            "style": "IPY_MODEL_59da986b885c42a6b8b484cb4392f3f2",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.98G/1.98G窶[00:19&lt;00:00,窶88.3MB/s]"
          }
        },
        "251c14a5ae174ecb8360700725ab495f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb58e0694a4c498f9de38b0b02ead236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cb0a49c8b04adcb70a8cdb9b4041e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b648c7146f7f40db850cf9f44ea1d67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29befda7086d446fb724a18c296cce37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36cd1ddcaa2b47bcb791c21bc4fbdbfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59da986b885c42a6b8b484cb4392f3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "7cd7423af9ef4d53a151ea966dc24490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a07637c436474d2d89b055a87fe1ec28",
              "IPY_MODEL_3c82d4fcc0284ac48edb7f1ab794b258",
              "IPY_MODEL_e331666673de406883c1d94a25f88a51"
            ],
            "layout": "IPY_MODEL_60141eeb5e714cf48d149abc96949c6b",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a07637c436474d2d89b055a87fe1ec28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ffc9911039fb4122a28ccab91bc5275d",
            "placeholder": "窶",
            "style": "IPY_MODEL_7df0c42d511647a1b1a35c498f094e3d",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00006-of-00008.safetensors:窶100%"
          }
        },
        "3c82d4fcc0284ac48edb7f1ab794b258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3dd49e8febc247ecaed4c4f64fc310b0",
            "max": 1946243984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3775399aae6148949a173355da623844",
            "tabbable": null,
            "tooltip": null,
            "value": 1946243984
          }
        },
        "e331666673de406883c1d94a25f88a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fce545d420c044808d8b1367d6307fe3",
            "placeholder": "窶",
            "style": "IPY_MODEL_63789564605d494db92d44597a675d6d",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.95G/1.95G窶[00:14&lt;00:00,窶61.5MB/s]"
          }
        },
        "60141eeb5e714cf48d149abc96949c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc9911039fb4122a28ccab91bc5275d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df0c42d511647a1b1a35c498f094e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3dd49e8febc247ecaed4c4f64fc310b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3775399aae6148949a173355da623844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fce545d420c044808d8b1367d6307fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63789564605d494db92d44597a675d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f959a97cbc20493e839764510696b2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a371593e315a40e3a12d5e12590daf1e",
              "IPY_MODEL_fb92ded1d6de42aca39193c4728e409b",
              "IPY_MODEL_06696fc6430d4c1499f597e54efd3b39"
            ],
            "layout": "IPY_MODEL_804a886b879a442cb53f93b1afec91bd",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a371593e315a40e3a12d5e12590daf1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f776d5f1937240e8b09bb27b8cdf24a2",
            "placeholder": "窶",
            "style": "IPY_MODEL_4b252f39078a41789a397e3d43dcb9ae",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00007-of-00008.safetensors:窶100%"
          }
        },
        "fb92ded1d6de42aca39193c4728e409b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f3831352808f4fafb37cf416c34628e4",
            "max": 1979781448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e037c1a251c416c806b7f5e77e88c4e",
            "tabbable": null,
            "tooltip": null,
            "value": 1979781448
          }
        },
        "06696fc6430d4c1499f597e54efd3b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_42908421bb064b419ff3dedfc256ead1",
            "placeholder": "窶",
            "style": "IPY_MODEL_57ed232488f34496a8c408b9cf760553",
            "tabbable": null,
            "tooltip": null,
            "value": "窶1.98G/1.98G窶[00:15&lt;00:00,窶195MB/s]"
          }
        },
        "804a886b879a442cb53f93b1afec91bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f776d5f1937240e8b09bb27b8cdf24a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b252f39078a41789a397e3d43dcb9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f3831352808f4fafb37cf416c34628e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e037c1a251c416c806b7f5e77e88c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42908421bb064b419ff3dedfc256ead1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ed232488f34496a8c408b9cf760553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "06f80e62a53d422694bb4696e8a3f761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df361455b624b2a880ac1c7a84e13aa",
              "IPY_MODEL_1cf20b529b494efca3be11908dab8958",
              "IPY_MODEL_110b08f7de98448197c046a03f8df4e4"
            ],
            "layout": "IPY_MODEL_f5ba6ba2075f48c99c9cd5be55940527",
            "tabbable": null,
            "tooltip": null
          }
        },
        "7df361455b624b2a880ac1c7a84e13aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_dc00ca65edcd4ee9a08ebd3b823df70c",
            "placeholder": "窶",
            "style": "IPY_MODEL_a54f6aaa898a4040a30d00a1edbfebfb",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00008-of-00008.safetensors:窶100%"
          }
        },
        "1cf20b529b494efca3be11908dab8958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ea7b2af229cb49a0b407559b92c9ff14",
            "max": 815834680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c32d0dc6af34a14a1fd523aea953413",
            "tabbable": null,
            "tooltip": null,
            "value": 815834680
          }
        },
        "110b08f7de98448197c046a03f8df4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6be2aec9450c45fbb2b42cf3f8136244",
            "placeholder": "窶",
            "style": "IPY_MODEL_b42f0543306e490dbee933081ea7955b",
            "tabbable": null,
            "tooltip": null,
            "value": "窶816M/816M窶[00:04&lt;00:00,窶86.0MB/s]"
          }
        },
        "f5ba6ba2075f48c99c9cd5be55940527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc00ca65edcd4ee9a08ebd3b823df70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54f6aaa898a4040a30d00a1edbfebfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ea7b2af229cb49a0b407559b92c9ff14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c32d0dc6af34a14a1fd523aea953413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6be2aec9450c45fbb2b42cf3f8136244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42f0543306e490dbee933081ea7955b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "90bd01835fe5461fb1c3134cc34186cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a39552e34b3849c88228df829c7005af",
              "IPY_MODEL_8c4379d96ae14a3eb2d2566ff9a076b2",
              "IPY_MODEL_41769859853f4abc954b61e121333bcf"
            ],
            "layout": "IPY_MODEL_3e153b470581473c8aa25e2a4f005b74",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a39552e34b3849c88228df829c7005af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f629b1522a214752bbbd5ad56d90f633",
            "placeholder": "窶",
            "style": "IPY_MODEL_684f3eff169440b8864e634806d50d58",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading窶checkpoint窶shards:窶100%"
          }
        },
        "8c4379d96ae14a3eb2d2566ff9a076b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7fc5a96d143149adbbdea6cb230cabb5",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fb8baf5e0534fe18a92c9351cef14e4",
            "tabbable": null,
            "tooltip": null,
            "value": 8
          }
        },
        "41769859853f4abc954b61e121333bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c2bce52d8feb4815804ff22db8728db6",
            "placeholder": "窶",
            "style": "IPY_MODEL_8bfd8f8d46e94af9b97b40f89bd10c50",
            "tabbable": null,
            "tooltip": null,
            "value": "窶8/8窶[01:13&lt;00:00,窶窶8.20s/it]"
          }
        },
        "3e153b470581473c8aa25e2a4f005b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f629b1522a214752bbbd5ad56d90f633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684f3eff169440b8864e634806d50d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "7fc5a96d143149adbbdea6cb230cabb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb8baf5e0534fe18a92c9351cef14e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2bce52d8feb4815804ff22db8728db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfd8f8d46e94af9b97b40f89bd10c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "02e7277aa92945288098d982b3b59faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6979fc817edf4a108aa079887f9a1747",
              "IPY_MODEL_cdf233c1ef3246bb9753845e1a53f27d",
              "IPY_MODEL_33c72ab8bb744ccaa9f4e7798643a85b"
            ],
            "layout": "IPY_MODEL_a7e3aff3c5754495a117fe51c75eafc3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6979fc817edf4a108aa079887f9a1747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_66357a9f41b540d0b63d9ac43213b1eb",
            "placeholder": "窶",
            "style": "IPY_MODEL_74f21d23cfe54eb7bb03b3cc7db0b164",
            "tabbable": null,
            "tooltip": null,
            "value": "generation_config.json:窶100%"
          }
        },
        "cdf233c1ef3246bb9753845e1a53f27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_754ebf586ef7400d9df2d5af979d75c7",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_978d8a77a2f64880b396fdcd7e4b2963",
            "tabbable": null,
            "tooltip": null,
            "value": 111
          }
        },
        "33c72ab8bb744ccaa9f4e7798643a85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fcb591adeb8c4caeb962dd31869bb56d",
            "placeholder": "窶",
            "style": "IPY_MODEL_e33ed70e2dd442c2bd52cb5de606a930",
            "tabbable": null,
            "tooltip": null,
            "value": "窶111/111窶[00:00&lt;00:00,窶7.58kB/s]"
          }
        },
        "a7e3aff3c5754495a117fe51c75eafc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66357a9f41b540d0b63d9ac43213b1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f21d23cfe54eb7bb03b3cc7db0b164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "754ebf586ef7400d9df2d5af979d75c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978d8a77a2f64880b396fdcd7e4b2963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcb591adeb8c4caeb962dd31869bb56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33ed70e2dd442c2bd52cb5de606a930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fdf70a053342484585f60bf4988d3b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d375ea82943e492997d30df85c65fe8b",
              "IPY_MODEL_cdc97c12fa744aa39556159a41f270f6",
              "IPY_MODEL_4f679ee3652346f79b0acc56b51c7e58"
            ],
            "layout": "IPY_MODEL_9edf4cbbc23e44faa011d34914bf84bd",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d375ea82943e492997d30df85c65fe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ac9f68ae1db84b9a97b700538df75da1",
            "placeholder": "窶",
            "style": "IPY_MODEL_b8662fb7af1b40e4af0a5eabf05352bf",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading窶checkpoint窶shards:窶100%"
          }
        },
        "cdc97c12fa744aa39556159a41f270f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_0e491331422f4cc3beb39787c3b6e468",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62dddbfe2a2446029e0fcf4b9a61835e",
            "tabbable": null,
            "tooltip": null,
            "value": 8
          }
        },
        "4f679ee3652346f79b0acc56b51c7e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_588ef6e2a6c04ff38321527deba161e5",
            "placeholder": "窶",
            "style": "IPY_MODEL_580f296252e44348ae2c97e91e59292b",
            "tabbable": null,
            "tooltip": null,
            "value": "窶8/8窶[01:11&lt;00:00,窶窶7.94s/it]"
          }
        },
        "9edf4cbbc23e44faa011d34914bf84bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9f68ae1db84b9a97b700538df75da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8662fb7af1b40e4af0a5eabf05352bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "0e491331422f4cc3beb39787c3b6e468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dddbfe2a2446029e0fcf4b9a61835e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "588ef6e2a6c04ff38321527deba161e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580f296252e44348ae2c97e91e59292b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}